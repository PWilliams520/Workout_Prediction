{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for building Logistic Regression model: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update the path to the activities.csv file from the repository\n",
    "df = pd.read_csv('activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Moving Time</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "      <th>Avg Moving Speed (kph)</th>\n",
       "      <th>Avg Pace (/km)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Best 20min Speed (kph)</th>\n",
       "      <th>...</th>\n",
       "      <th>HRSS / h</th>\n",
       "      <th>Best 20min HR (bpm)</th>\n",
       "      <th>Cadence Avg Moving (rpm or spm)</th>\n",
       "      <th>Avg Watts (w)</th>\n",
       "      <th>Avg Watts / Kilograms (w/kg)</th>\n",
       "      <th>Best 20min Power (w)</th>\n",
       "      <th>Power Stress Score</th>\n",
       "      <th>Power Stress Score / h</th>\n",
       "      <th>Athlete Settings</th>\n",
       "      <th>Delete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-22T16:27:01-04:00</td>\n",
       "      <td>Último día de verano</td>\n",
       "      <td>Ride</td>\n",
       "      <td>01:58:06</td>\n",
       "      <td>62.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>31.7</td>\n",
       "      <td>01:53</td>\n",
       "      <td>1772</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>163</td>\n",
       "      <td>95</td>\n",
       "      <td>179</td>\n",
       "      <td>2.56</td>\n",
       "      <td>201</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxHr 190bpm. RestHr 65bpm. Weight 70kg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-21T11:57:23-04:00</td>\n",
       "      <td>Dos loops</td>\n",
       "      <td>Ride</td>\n",
       "      <td>02:38:51</td>\n",
       "      <td>80.1</td>\n",
       "      <td>890.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>02:05</td>\n",
       "      <td>2432</td>\n",
       "      <td>36.7</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>173</td>\n",
       "      <td>89</td>\n",
       "      <td>174</td>\n",
       "      <td>2.49</td>\n",
       "      <td>225</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxHr 190bpm. RestHr 65bpm. Weight 70kg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-20T17:55:47-04:00</td>\n",
       "      <td>Con poco tiempo</td>\n",
       "      <td>Ride</td>\n",
       "      <td>01:07:52</td>\n",
       "      <td>35.2</td>\n",
       "      <td>314.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>01:56</td>\n",
       "      <td>1029</td>\n",
       "      <td>34.5</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>163</td>\n",
       "      <td>91</td>\n",
       "      <td>169</td>\n",
       "      <td>2.42</td>\n",
       "      <td>188</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxHr 190bpm. RestHr 65bpm. Weight 70kg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-19T23:45:00-04:00</td>\n",
       "      <td>Complimentary calisthenics</td>\n",
       "      <td>Workout</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Weight 70kg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-18T17:41:48-04:00</td>\n",
       "      <td>Afternoon Ride</td>\n",
       "      <td>Ride</td>\n",
       "      <td>01:26:05</td>\n",
       "      <td>45.6</td>\n",
       "      <td>447.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>01:54</td>\n",
       "      <td>1326</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>173</td>\n",
       "      <td>97</td>\n",
       "      <td>181</td>\n",
       "      <td>2.59</td>\n",
       "      <td>221</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxHr 190bpm. RestHr 65bpm. Weight 70kg.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date                        Name     Type Moving Time  \\\n",
       "0  2019-09-22T16:27:01-04:00        Último día de verano     Ride    01:58:06   \n",
       "1  2019-09-21T11:57:23-04:00                   Dos loops     Ride    02:38:51   \n",
       "2  2019-09-20T17:55:47-04:00             Con poco tiempo     Ride    01:07:52   \n",
       "3  2019-09-19T23:45:00-04:00  Complimentary calisthenics  Workout    01:00:00   \n",
       "4  2019-09-18T17:41:48-04:00              Afternoon Ride     Ride    01:26:05   \n",
       "\n",
       "   Distance (km)  Elevation Gain (m) Avg Moving Speed (kph) Avg Pace (/km)  \\\n",
       "0           62.5               589.0                   31.7          01:53   \n",
       "1           80.1               890.0                   28.7          02:05   \n",
       "2           35.2               314.0                   30.9          01:56   \n",
       "3            0.0                 0.0                      -              -   \n",
       "4           45.6               447.0                   31.4          01:54   \n",
       "\n",
       "  Calories Best 20min Speed (kph)  ... HRSS / h Best 20min HR (bpm)  \\\n",
       "0     1772                     34  ...       73                 163   \n",
       "1     2432                   36.7  ...       77                 173   \n",
       "2     1029                   34.5  ...       76                 163   \n",
       "3        -                      -  ...        -                   -   \n",
       "4     1326                     36  ...       81                 173   \n",
       "\n",
       "  Cadence Avg Moving (rpm or spm) Avg Watts (w) Avg Watts / Kilograms (w/kg)  \\\n",
       "0                              95           179                         2.56   \n",
       "1                              89           174                         2.49   \n",
       "2                              91           169                         2.42   \n",
       "3                               -             -                            -   \n",
       "4                              97           181                         2.59   \n",
       "\n",
       "  Best 20min Power (w) Power Stress Score Power Stress Score / h  \\\n",
       "0                  201                  -                      0   \n",
       "1                  225                  -                      0   \n",
       "2                  188                  -                      0   \n",
       "3                    -                  -                      -   \n",
       "4                  221                  -                      0   \n",
       "\n",
       "                           Athlete Settings Delete  \n",
       "0  MaxHr 190bpm. RestHr 65bpm. Weight 70kg.    NaN  \n",
       "1  MaxHr 190bpm. RestHr 65bpm. Weight 70kg.    NaN  \n",
       "2  MaxHr 190bpm. RestHr 65bpm. Weight 70kg.    NaN  \n",
       "3                              Weight 70kg.    NaN  \n",
       "4  MaxHr 190bpm. RestHr 65bpm. Weight 70kg.    NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>573.000000</td>\n",
       "      <td>573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.888656</td>\n",
       "      <td>620.718325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.855291</td>\n",
       "      <td>601.756726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.300000</td>\n",
       "      <td>189.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.900000</td>\n",
       "      <td>526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.900000</td>\n",
       "      <td>884.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170.600000</td>\n",
       "      <td>3617.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Distance (km)  Elevation Gain (m)\n",
       "count     573.000000          573.000000\n",
       "mean       35.888656          620.718325\n",
       "std        29.855291          601.756726\n",
       "min         0.000000            0.000000\n",
       "25%         9.300000          189.400000\n",
       "50%        32.900000          526.000000\n",
       "75%        51.900000          884.600000\n",
       "max       170.600000         3617.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before feature pre-processing\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Avg HR (bpm)'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-723aa70d1045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select features and rename columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Avg HR (bpm)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Distance (km)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Avg Pace (/km)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Calories'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HRSS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Elevation Gain (m)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Avg HR (bpm)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"AvgHR\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1269\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         )\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Avg HR (bpm)'] not in index\""
     ]
    }
   ],
   "source": [
    "# Select features and rename columns\n",
    "df = df[['Avg HR (bpm)','Date','Type','Distance (km)','Avg Pace (/km)','Calories','HRSS','Elevation Gain (m)']]\n",
    "df = df.rename(columns={\"Avg HR (bpm)\": \"AvgHR\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgHR</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Avg Pace (/km)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>HRSS</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>155.032362</td>\n",
       "      <td>52.237540</td>\n",
       "      <td>150.624595</td>\n",
       "      <td>1573.423948</td>\n",
       "      <td>152.022654</td>\n",
       "      <td>888.765372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.505282</td>\n",
       "      <td>27.117491</td>\n",
       "      <td>42.469105</td>\n",
       "      <td>848.025054</td>\n",
       "      <td>82.021593</td>\n",
       "      <td>650.796847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149.000000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>979.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>492.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>1354.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>715.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>60.400000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>1827.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>1128.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>170.600000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>5415.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>3617.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AvgHR  Distance (km)  Avg Pace (/km)     Calories        HRSS  \\\n",
       "count  309.000000     309.000000      309.000000   309.000000  309.000000   \n",
       "mean   155.032362      52.237540      150.624595  1573.423948  152.022654   \n",
       "std     12.505282      27.117491       42.469105   848.025054   82.021593   \n",
       "min     84.000000       1.400000       86.000000    48.000000    3.000000   \n",
       "25%    149.000000      32.900000      119.000000   979.000000   98.000000   \n",
       "50%    155.000000      50.100000      151.000000  1354.000000  128.000000   \n",
       "75%    161.000000      60.400000      168.000000  1827.000000  187.000000   \n",
       "max    191.000000     170.600000      477.000000  5415.000000  471.000000   \n",
       "\n",
       "       Elevation Gain (m)  \n",
       "count          309.000000  \n",
       "mean           888.765372  \n",
       "std            650.796847  \n",
       "min              0.000000  \n",
       "25%            492.000000  \n",
       "50%            715.000000  \n",
       "75%           1128.900000  \n",
       "max           3617.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features and pre-process data for final dataset\n",
    "from dateutil.parser import parse\n",
    "# Filter rows to include only those with AvgHR\n",
    "df = df[df.AvgHR != '-']\n",
    "# Only include Ride and VirtualRide types\n",
    "types = ['Ride', 'VirtualRide']\n",
    "df = df[df.Type.isin(types)]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "# Convert features to numbers\n",
    "df[\"AvgHR\"] = pd.to_numeric(df[\"AvgHR\"])\n",
    "df[\"Calories\"] = pd.to_numeric(df[\"Calories\"])\n",
    "df[\"HRSS\"] = pd.to_numeric(df[\"HRSS\"])\n",
    "df.head()\n",
    "# Convert Avg Pace to seconds, parse Date and Time as separate columns\n",
    "for i in range(df.shape[0]):\n",
    "    #print('done')\n",
    "    #print(df.loc[i,'Avg Pace (/km)'])\n",
    "    (m, s) = str(df.loc[i,'Avg Pace (/km)']).split(':')\n",
    "    df.loc[i,'Avg Pace (/km)']= (int(m) * 60) + int(s)\n",
    "    dt = parse(df.loc[i,'Date'])\n",
    "    df.loc[i,'Date'] = dt.date()\n",
    "    df.loc[i,'Time'] = dt.time()\n",
    "# Convert Avg Pace to number\n",
    "df['Avg Pace (/km)'] = pd.to_numeric(df['Avg Pace (/km)'])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgHR</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Avg Pace (/km)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>HRSS</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ride</th>\n",
       "      <td>154.535593</td>\n",
       "      <td>53.271525</td>\n",
       "      <td>152.298305</td>\n",
       "      <td>1615.294915</td>\n",
       "      <td>155.122034</td>\n",
       "      <td>912.209831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VirtualRide</th>\n",
       "      <td>165.500000</td>\n",
       "      <td>30.450000</td>\n",
       "      <td>115.357143</td>\n",
       "      <td>691.142857</td>\n",
       "      <td>86.714286</td>\n",
       "      <td>394.757143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AvgHR  Distance (km)  Avg Pace (/km)     Calories  \\\n",
       "Type                                                                  \n",
       "Ride         154.535593      53.271525      152.298305  1615.294915   \n",
       "VirtualRide  165.500000      30.450000      115.357143   691.142857   \n",
       "\n",
       "                   HRSS  Elevation Gain (m)  \n",
       "Type                                         \n",
       "Ride         155.122034          912.209831  \n",
       "VirtualRide   86.714286          394.757143  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Type']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">AvgHR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Distance (km)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HRSS</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Elevation Gain (m)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ride</th>\n",
       "      <td>295.0</td>\n",
       "      <td>154.535593</td>\n",
       "      <td>12.103490</td>\n",
       "      <td>84.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>155.0</td>\n",
       "      <td>160.50</td>\n",
       "      <td>191.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>53.271525</td>\n",
       "      <td>...</td>\n",
       "      <td>189.5</td>\n",
       "      <td>471.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>912.209831</td>\n",
       "      <td>656.472151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1131.85</td>\n",
       "      <td>3617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VirtualRide</th>\n",
       "      <td>14.0</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>16.383622</td>\n",
       "      <td>135.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>163.0</td>\n",
       "      <td>175.75</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>394.757143</td>\n",
       "      <td>114.192663</td>\n",
       "      <td>230.6</td>\n",
       "      <td>301.0</td>\n",
       "      <td>368.5</td>\n",
       "      <td>500.00</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AvgHR                                                       \\\n",
       "             count        mean        std    min     25%    50%     75%   \n",
       "Type                                                                      \n",
       "Ride         295.0  154.535593  12.103490   84.0  149.00  155.0  160.50   \n",
       "VirtualRide   14.0  165.500000  16.383622  135.0  156.75  163.0  175.75   \n",
       "\n",
       "                   Distance (km)             ...   HRSS         \\\n",
       "               max         count       mean  ...    75%    max   \n",
       "Type                                         ...                 \n",
       "Ride         191.0         295.0  53.271525  ...  189.5  471.0   \n",
       "VirtualRide  191.0          14.0  30.450000  ...   94.0  127.0   \n",
       "\n",
       "            Elevation Gain (m)                                               \\\n",
       "                         count        mean         std    min    25%    50%   \n",
       "Type                                                                          \n",
       "Ride                     295.0  912.209831  656.472151    0.0  512.0  743.0   \n",
       "VirtualRide               14.0  394.757143  114.192663  230.6  301.0  368.5   \n",
       "\n",
       "                              \n",
       "                 75%     max  \n",
       "Type                          \n",
       "Ride         1131.85  3617.0  \n",
       "VirtualRide   500.00   558.0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Type']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary labels for High 'AvgHR' (1) and Low 'AvgHR' (0) based on threshold of 154 bpm\n",
    "for j in range(df.shape[0]):\n",
    "    if int(df.loc[j,'AvgHR']) > 154:\n",
    "        #print(df.loc[j,'AvgHR'])\n",
    "        df.loc[j,'AvgHR_bin'] = 1\n",
    "    else: \n",
    "        df.loc[j,'AvgHR_bin'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgHR</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Avg Pace (/km)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>HRSS</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "      <th>Time</th>\n",
       "      <th>AvgHR_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>Ride</td>\n",
       "      <td>62.5</td>\n",
       "      <td>113</td>\n",
       "      <td>1772</td>\n",
       "      <td>144</td>\n",
       "      <td>589.0</td>\n",
       "      <td>16:27:01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Ride</td>\n",
       "      <td>80.1</td>\n",
       "      <td>125</td>\n",
       "      <td>2432</td>\n",
       "      <td>217</td>\n",
       "      <td>890.0</td>\n",
       "      <td>11:57:23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>Ride</td>\n",
       "      <td>35.2</td>\n",
       "      <td>116</td>\n",
       "      <td>1029</td>\n",
       "      <td>87</td>\n",
       "      <td>314.0</td>\n",
       "      <td>17:55:47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>Ride</td>\n",
       "      <td>45.6</td>\n",
       "      <td>114</td>\n",
       "      <td>1326</td>\n",
       "      <td>119</td>\n",
       "      <td>447.0</td>\n",
       "      <td>17:41:48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Ride</td>\n",
       "      <td>41.1</td>\n",
       "      <td>120</td>\n",
       "      <td>1156</td>\n",
       "      <td>96</td>\n",
       "      <td>454.0</td>\n",
       "      <td>16:47:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>Ride</td>\n",
       "      <td>61.4</td>\n",
       "      <td>122</td>\n",
       "      <td>1806</td>\n",
       "      <td>146</td>\n",
       "      <td>692.0</td>\n",
       "      <td>12:00:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>158</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>Ride</td>\n",
       "      <td>81.0</td>\n",
       "      <td>129</td>\n",
       "      <td>2550</td>\n",
       "      <td>225</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>12:30:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>142</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>Ride</td>\n",
       "      <td>51.4</td>\n",
       "      <td>128</td>\n",
       "      <td>1289</td>\n",
       "      <td>90</td>\n",
       "      <td>576.0</td>\n",
       "      <td>10:32:05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>153</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>Ride</td>\n",
       "      <td>55.4</td>\n",
       "      <td>114</td>\n",
       "      <td>1479</td>\n",
       "      <td>116</td>\n",
       "      <td>502.0</td>\n",
       "      <td>17:55:23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154</td>\n",
       "      <td>2019-09-10</td>\n",
       "      <td>Ride</td>\n",
       "      <td>47.2</td>\n",
       "      <td>116</td>\n",
       "      <td>1288</td>\n",
       "      <td>106</td>\n",
       "      <td>447.0</td>\n",
       "      <td>18:37:38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>168</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.6</td>\n",
       "      <td>122</td>\n",
       "      <td>1744</td>\n",
       "      <td>172</td>\n",
       "      <td>535.0</td>\n",
       "      <td>13:55:36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>165</td>\n",
       "      <td>2019-09-07</td>\n",
       "      <td>Ride</td>\n",
       "      <td>100.9</td>\n",
       "      <td>130</td>\n",
       "      <td>3490</td>\n",
       "      <td>337</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>15:00:09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>166</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.0</td>\n",
       "      <td>116</td>\n",
       "      <td>1635</td>\n",
       "      <td>152</td>\n",
       "      <td>560.0</td>\n",
       "      <td>16:45:29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>151</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>Ride</td>\n",
       "      <td>13.2</td>\n",
       "      <td>301</td>\n",
       "      <td>900</td>\n",
       "      <td>74</td>\n",
       "      <td>184.0</td>\n",
       "      <td>17:40:32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>162</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>VirtualRide</td>\n",
       "      <td>30.3</td>\n",
       "      <td>127</td>\n",
       "      <td>729</td>\n",
       "      <td>92</td>\n",
       "      <td>550.0</td>\n",
       "      <td>17:27:57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>136</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>Ride</td>\n",
       "      <td>45.9</td>\n",
       "      <td>148</td>\n",
       "      <td>1114</td>\n",
       "      <td>79</td>\n",
       "      <td>447.0</td>\n",
       "      <td>16:10:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>Ride</td>\n",
       "      <td>32.5</td>\n",
       "      <td>119</td>\n",
       "      <td>855</td>\n",
       "      <td>66</td>\n",
       "      <td>282.0</td>\n",
       "      <td>17:53:27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>165</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>Ride</td>\n",
       "      <td>47.5</td>\n",
       "      <td>110</td>\n",
       "      <td>1393</td>\n",
       "      <td>132</td>\n",
       "      <td>406.0</td>\n",
       "      <td>17:45:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>150</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>Ride</td>\n",
       "      <td>63.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1661</td>\n",
       "      <td>128</td>\n",
       "      <td>744.0</td>\n",
       "      <td>15:55:11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>158</td>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>Ride</td>\n",
       "      <td>55.4</td>\n",
       "      <td>108</td>\n",
       "      <td>1495</td>\n",
       "      <td>123</td>\n",
       "      <td>541.0</td>\n",
       "      <td>15:03:44</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161</td>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.8</td>\n",
       "      <td>116</td>\n",
       "      <td>1568</td>\n",
       "      <td>138</td>\n",
       "      <td>605.0</td>\n",
       "      <td>10:46:38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>141</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>Ride</td>\n",
       "      <td>50.6</td>\n",
       "      <td>187</td>\n",
       "      <td>1761</td>\n",
       "      <td>133</td>\n",
       "      <td>981.0</td>\n",
       "      <td>11:00:18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>142</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>Ride</td>\n",
       "      <td>55.2</td>\n",
       "      <td>149</td>\n",
       "      <td>1578</td>\n",
       "      <td>116</td>\n",
       "      <td>884.0</td>\n",
       "      <td>13:41:35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>149</td>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>Ride</td>\n",
       "      <td>139.8</td>\n",
       "      <td>151</td>\n",
       "      <td>4400</td>\n",
       "      <td>390</td>\n",
       "      <td>2768.3</td>\n",
       "      <td>10:54:51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>142</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>Ride</td>\n",
       "      <td>40.3</td>\n",
       "      <td>266</td>\n",
       "      <td>1979</td>\n",
       "      <td>166</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>09:42:11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>145</td>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>Ride</td>\n",
       "      <td>64.2</td>\n",
       "      <td>195</td>\n",
       "      <td>2405</td>\n",
       "      <td>195</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>14:09:44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>140</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.9</td>\n",
       "      <td>193</td>\n",
       "      <td>1823</td>\n",
       "      <td>137</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>11:27:46</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>Ride</td>\n",
       "      <td>15.1</td>\n",
       "      <td>477</td>\n",
       "      <td>788</td>\n",
       "      <td>71</td>\n",
       "      <td>492.0</td>\n",
       "      <td>14:40:02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>142</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>Ride</td>\n",
       "      <td>141.0</td>\n",
       "      <td>167</td>\n",
       "      <td>4315</td>\n",
       "      <td>354</td>\n",
       "      <td>3366.0</td>\n",
       "      <td>08:46:01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>137</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>Ride</td>\n",
       "      <td>27.2</td>\n",
       "      <td>221</td>\n",
       "      <td>989</td>\n",
       "      <td>82</td>\n",
       "      <td>636.0</td>\n",
       "      <td>12:28:11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>153</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>Ride</td>\n",
       "      <td>110.3</td>\n",
       "      <td>157</td>\n",
       "      <td>2756</td>\n",
       "      <td>335</td>\n",
       "      <td>2063.6</td>\n",
       "      <td>12:15:15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>152</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>Ride</td>\n",
       "      <td>51.9</td>\n",
       "      <td>154</td>\n",
       "      <td>1320</td>\n",
       "      <td>153</td>\n",
       "      <td>966.7</td>\n",
       "      <td>12:13:44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>153</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>Ride</td>\n",
       "      <td>50.3</td>\n",
       "      <td>160</td>\n",
       "      <td>1330</td>\n",
       "      <td>153</td>\n",
       "      <td>1131.8</td>\n",
       "      <td>11:40:30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>130</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>Ride</td>\n",
       "      <td>54.1</td>\n",
       "      <td>254</td>\n",
       "      <td>2134</td>\n",
       "      <td>142</td>\n",
       "      <td>1111.9</td>\n",
       "      <td>10:29:16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>155</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>Ride</td>\n",
       "      <td>51.9</td>\n",
       "      <td>155</td>\n",
       "      <td>1310</td>\n",
       "      <td>159</td>\n",
       "      <td>960.4</td>\n",
       "      <td>11:40:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>156</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>Ride</td>\n",
       "      <td>51.9</td>\n",
       "      <td>154</td>\n",
       "      <td>1323</td>\n",
       "      <td>166</td>\n",
       "      <td>968.8</td>\n",
       "      <td>10:27:07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>157</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>Ride</td>\n",
       "      <td>45.9</td>\n",
       "      <td>159</td>\n",
       "      <td>1126</td>\n",
       "      <td>156</td>\n",
       "      <td>822.0</td>\n",
       "      <td>12:25:22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>151</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.0</td>\n",
       "      <td>163</td>\n",
       "      <td>1302</td>\n",
       "      <td>157</td>\n",
       "      <td>970.3</td>\n",
       "      <td>11:24:39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>157</td>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>Ride</td>\n",
       "      <td>50.3</td>\n",
       "      <td>162</td>\n",
       "      <td>1354</td>\n",
       "      <td>179</td>\n",
       "      <td>1123.6</td>\n",
       "      <td>09:10:41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>149</td>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>Ride</td>\n",
       "      <td>51.9</td>\n",
       "      <td>164</td>\n",
       "      <td>1289</td>\n",
       "      <td>150</td>\n",
       "      <td>970.4</td>\n",
       "      <td>10:04:53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>126</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>Ride</td>\n",
       "      <td>40.6</td>\n",
       "      <td>233</td>\n",
       "      <td>932</td>\n",
       "      <td>86</td>\n",
       "      <td>716.4</td>\n",
       "      <td>09:07:22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>154</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>Ride</td>\n",
       "      <td>124.3</td>\n",
       "      <td>159</td>\n",
       "      <td>3343</td>\n",
       "      <td>391</td>\n",
       "      <td>2602.0</td>\n",
       "      <td>10:25:48</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>160</td>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>Ride</td>\n",
       "      <td>53.4</td>\n",
       "      <td>151</td>\n",
       "      <td>1460</td>\n",
       "      <td>187</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>11:35:45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>156</td>\n",
       "      <td>2017-09-25</td>\n",
       "      <td>Ride</td>\n",
       "      <td>53.4</td>\n",
       "      <td>152</td>\n",
       "      <td>1443</td>\n",
       "      <td>169</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>10:46:22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>147</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>Ride</td>\n",
       "      <td>40.3</td>\n",
       "      <td>170</td>\n",
       "      <td>1050</td>\n",
       "      <td>115</td>\n",
       "      <td>794.6</td>\n",
       "      <td>13:19:29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>145</td>\n",
       "      <td>2017-09-16</td>\n",
       "      <td>Ride</td>\n",
       "      <td>50.1</td>\n",
       "      <td>169</td>\n",
       "      <td>1321</td>\n",
       "      <td>132</td>\n",
       "      <td>898.0</td>\n",
       "      <td>12:41:17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>155</td>\n",
       "      <td>2017-09-15</td>\n",
       "      <td>Ride</td>\n",
       "      <td>53.8</td>\n",
       "      <td>157</td>\n",
       "      <td>1473</td>\n",
       "      <td>171</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>11:49:10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>154</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>Ride</td>\n",
       "      <td>70.5</td>\n",
       "      <td>148</td>\n",
       "      <td>1842</td>\n",
       "      <td>201</td>\n",
       "      <td>1206.5</td>\n",
       "      <td>08:53:53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>151</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>Ride</td>\n",
       "      <td>74.9</td>\n",
       "      <td>152</td>\n",
       "      <td>1988</td>\n",
       "      <td>205</td>\n",
       "      <td>1262.1</td>\n",
       "      <td>10:46:54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>156</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>Ride</td>\n",
       "      <td>55.5</td>\n",
       "      <td>115</td>\n",
       "      <td>1177</td>\n",
       "      <td>123</td>\n",
       "      <td>495.6</td>\n",
       "      <td>08:27:30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>153</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>Ride</td>\n",
       "      <td>33.8</td>\n",
       "      <td>146</td>\n",
       "      <td>953</td>\n",
       "      <td>93</td>\n",
       "      <td>631.6</td>\n",
       "      <td>11:24:40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>129</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>Ride</td>\n",
       "      <td>45.1</td>\n",
       "      <td>272</td>\n",
       "      <td>1758</td>\n",
       "      <td>124</td>\n",
       "      <td>1061.1</td>\n",
       "      <td>11:47:04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>154</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>Ride</td>\n",
       "      <td>72.7</td>\n",
       "      <td>148</td>\n",
       "      <td>1877</td>\n",
       "      <td>208</td>\n",
       "      <td>1239.2</td>\n",
       "      <td>10:14:13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>149</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>Ride</td>\n",
       "      <td>53.4</td>\n",
       "      <td>167</td>\n",
       "      <td>1514</td>\n",
       "      <td>156</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>10:57:14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>126</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>Ride</td>\n",
       "      <td>41.1</td>\n",
       "      <td>267</td>\n",
       "      <td>1604</td>\n",
       "      <td>102</td>\n",
       "      <td>938.0</td>\n",
       "      <td>11:34:17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>149</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>Ride</td>\n",
       "      <td>70.9</td>\n",
       "      <td>146</td>\n",
       "      <td>1817</td>\n",
       "      <td>175</td>\n",
       "      <td>1202.7</td>\n",
       "      <td>10:09:39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>148</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>Ride</td>\n",
       "      <td>70.1</td>\n",
       "      <td>159</td>\n",
       "      <td>1827</td>\n",
       "      <td>191</td>\n",
       "      <td>1185.3</td>\n",
       "      <td>11:44:59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>150</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>Ride</td>\n",
       "      <td>53.7</td>\n",
       "      <td>163</td>\n",
       "      <td>1432</td>\n",
       "      <td>161</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>13:41:10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>131</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>Ride</td>\n",
       "      <td>40.5</td>\n",
       "      <td>161</td>\n",
       "      <td>941</td>\n",
       "      <td>70</td>\n",
       "      <td>350.4</td>\n",
       "      <td>13:14:20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>151</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>Ride</td>\n",
       "      <td>52.0</td>\n",
       "      <td>138</td>\n",
       "      <td>1332</td>\n",
       "      <td>126</td>\n",
       "      <td>811.4</td>\n",
       "      <td>09:32:39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AvgHR        Date  Type  Distance (km)  Avg Pace (/km)  Calories  HRSS  \\\n",
       "0      158  2019-09-22  Ride           62.5             113      1772   144   \n",
       "1      158  2019-09-21  Ride           80.1             125      2432   217   \n",
       "2      159  2019-09-20  Ride           35.2             116      1029    87   \n",
       "3      161  2019-09-18  Ride           45.6             114      1326   119   \n",
       "4      155  2019-09-17  Ride           41.1             120      1156    96   \n",
       "..     ...         ...   ...            ...             ...       ...   ...   \n",
       "304    149  2017-08-18  Ride           70.9             146      1817   175   \n",
       "305    148  2017-08-16  Ride           70.1             159      1827   191   \n",
       "306    150  2017-08-14  Ride           53.7             163      1432   161   \n",
       "307    131  2017-08-13  Ride           40.5             161       941    70   \n",
       "308    151  2017-08-05  Ride           52.0             138      1332   126   \n",
       "\n",
       "     Elevation Gain (m)      Time  AvgHR_bin  \n",
       "0                 589.0  16:27:01        1.0  \n",
       "1                 890.0  11:57:23        1.0  \n",
       "2                 314.0  17:55:47        1.0  \n",
       "3                 447.0  17:41:48        1.0  \n",
       "4                 454.0  16:47:31        1.0  \n",
       "..                  ...       ...        ...  \n",
       "304              1202.7  10:09:39        0.0  \n",
       "305              1185.3  11:44:59        0.0  \n",
       "306              1015.8  13:41:10        0.0  \n",
       "307               350.4  13:14:20        0.0  \n",
       "308               811.4  09:32:39        0.0  \n",
       "\n",
       "[309 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgHR</th>\n",
       "      <th>Distance (km)</th>\n",
       "      <th>Avg Pace (/km)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>HRSS</th>\n",
       "      <th>Elevation Gain (m)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgHR_bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>145.794521</td>\n",
       "      <td>55.214384</td>\n",
       "      <td>167.794521</td>\n",
       "      <td>1644.650685</td>\n",
       "      <td>145.445205</td>\n",
       "      <td>1048.490411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>163.306748</td>\n",
       "      <td>49.571166</td>\n",
       "      <td>135.245399</td>\n",
       "      <td>1509.625767</td>\n",
       "      <td>157.914110</td>\n",
       "      <td>745.698773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AvgHR  Distance (km)  Avg Pace (/km)     Calories        HRSS  \\\n",
       "AvgHR_bin                                                                       \n",
       "0.0        145.794521      55.214384      167.794521  1644.650685  145.445205   \n",
       "1.0        163.306748      49.571166      135.245399  1509.625767  157.914110   \n",
       "\n",
       "           Elevation Gain (m)  \n",
       "AvgHR_bin                      \n",
       "0.0               1048.490411  \n",
       "1.0                745.698773  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('AvgHR_bin').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/pandas/plotting/_matplotlib/converter.py:102: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot AvgHR over time for all virtual and outdoor bike rides\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot_date(df['Date'],df['AvgHR'])\n",
    "plt.title('AvgHR Over Time for Rides')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('AvgHR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of High AvgHR is 52.75\n",
      "percentage of Low AvgHR is 47.25\n"
     ]
    }
   ],
   "source": [
    "# Calculate sample size of each class\n",
    "count_no_sub = len(df[df['AvgHR_bin']==1])\n",
    "count_sub = len(df[df['AvgHR_bin']==0])\n",
    "pct_of_no_sub = count_no_sub/(count_no_sub+count_sub)\n",
    "print(\"percentage of High AvgHR is\", '%.2f' %(pct_of_no_sub*100))\n",
    "pct_of_sub = count_sub/(count_no_sub+count_sub)\n",
    "print(\"percentage of Low AvgHR is\", '%.2f' %(pct_of_sub*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency of Average HR')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of AvgHR for Rides and VirtualRides\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.crosstab(df.Type,df.AvgHR_bin).plot(kind='bar')\n",
    "plt.title('Average HR for Type')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Frequency of Average HR')\n",
    "#plt.savefig('purchase_avghr_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Distance (km)  Avg Pace (/km)  HRSS  Elevation Gain (m)\n",
      "0           62.5             113   144               589.0\n",
      "1           80.1             125   217               890.0\n",
      "2           35.2             116    87               314.0\n",
      "3           45.6             114   119               447.0\n",
      "4           41.1             120    96               454.0\n",
      "5           61.4             122   146               692.0\n",
      "6           81.0             129   225              1096.0\n",
      "7           51.4             128    90               576.0\n",
      "8           55.4             114   116               502.0\n",
      "9           47.2             116   106               447.0    AvgHR\n",
      "0    158\n",
      "1    158\n",
      "2    159\n",
      "3    161\n",
      "4    155\n",
      "5    155\n",
      "6    158\n",
      "7    142\n",
      "8    153\n",
      "9    154\n",
      "[ True  True  True  True]\n",
      "[1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/srv/conda/envs/notebook/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define train and test set, perform RFE\n",
    "window_size = 10\n",
    "# removed Calories as feature since p-value was 0.07 > 0.05 (from below Logit function), as recommended\n",
    "df_vars = ['Distance (km)', 'Avg Pace (/km)', 'HRSS', 'Elevation Gain (m)','AvgHR']\n",
    "df_final = df[df_vars]\n",
    "df_final_vars=df_final.columns.values.tolist()\n",
    "y=df_final.AvgHR\n",
    "X=[i for i in df_final_vars if i not in y]\n",
    "\n",
    "X = df_final.loc[:, df_final.columns != 'AvgHR']\n",
    "y = df_final.loc[:, df_final.columns == 'AvgHR']\n",
    "\n",
    "# Configure train and test sets\n",
    "X_train = X.iloc[window_size:]\n",
    "y_train = y.iloc[window_size:]\n",
    "\n",
    "X_test = X.iloc[:window_size]\n",
    "y_test = y.iloc[:window_size]\n",
    "print(X_test, y_test)\n",
    "\n",
    "# Perform RFE (recursive feature elimination) to determine ranking of features\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Logit model to determine p-values and coefficients for each feature\n",
    "# import statsmodels\n",
    "# import statsmodels.api as sm\n",
    "# logit_model=sm.Logit(y,X)\n",
    "# result=logit_model.fit()\n",
    "# print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Gradient Boosting with LOO and window size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  10\n",
      "Window Size:  299\n",
      "train labels:       AvgHR\n",
      "10     168\n",
      "11     165\n",
      "12     166\n",
      "13     151\n",
      "14     162\n",
      "..     ...\n",
      "304    149\n",
      "305    148\n",
      "306    150\n",
      "307    131\n",
      "308    151\n",
      "\n",
      "[299 rows x 1 columns]\n",
      "test labels:     AvgHR\n",
      "0    158\n",
      "1    158\n",
      "2    159\n",
      "3    161\n",
      "4    155\n",
      "5    155\n",
      "6    158\n",
      "7    142\n",
      "8    153\n",
      "9    154\n",
      "Iteration:  0\n",
      "X train shape:  299\n",
      "X test shape:  10\n",
      "actual:  AvgHR    154\n",
      "Name: 9, dtype: int64 \n",
      " pred:  [155.56509123] \n",
      "\n",
      "mse:  2.449510571825972\n",
      "Iteration:  1\n",
      "X train shape:  299\n",
      "X test shape:  9\n",
      "actual:  AvgHR    153\n",
      "Name: 8, dtype: int64 \n",
      " pred:  [155.63401368] \n",
      "\n",
      "mse:  6.938028085488704\n",
      "Iteration:  2\n",
      "X train shape:  299\n",
      "X test shape:  8\n",
      "actual:  AvgHR    142\n",
      "Name: 7, dtype: int64 \n",
      " pred:  [149.41845746] \n",
      "\n",
      "mse:  55.03351112055058\n",
      "Iteration:  3\n",
      "X train shape:  299\n",
      "X test shape:  7\n",
      "actual:  AvgHR    158\n",
      "Name: 6, dtype: int64 \n",
      " pred:  [155.82144515] \n",
      "\n",
      "mse:  4.7461012390277695\n",
      "Iteration:  4\n",
      "X train shape:  299\n",
      "X test shape:  6\n",
      "actual:  AvgHR    155\n",
      "Name: 5, dtype: int64 \n",
      " pred:  [158.76580918] \n",
      "\n",
      "mse:  14.18131880404284\n",
      "Iteration:  5\n",
      "X train shape:  299\n",
      "X test shape:  5\n",
      "actual:  AvgHR    155\n",
      "Name: 4, dtype: int64 \n",
      " pred:  [154.29761684] \n",
      "\n",
      "mse:  0.49334209891414654\n",
      "Iteration:  6\n",
      "X train shape:  299\n",
      "X test shape:  4\n",
      "actual:  AvgHR    161\n",
      "Name: 3, dtype: int64 \n",
      " pred:  [158.40466973] \n",
      "\n",
      "mse:  6.735739205614639\n",
      "Iteration:  7\n",
      "X train shape:  299\n",
      "X test shape:  3\n",
      "actual:  AvgHR    159\n",
      "Name: 2, dtype: int64 \n",
      " pred:  [156.34584825] \n",
      "\n",
      "mse:  7.044521498757201\n",
      "Iteration:  8\n",
      "X train shape:  299\n",
      "X test shape:  2\n",
      "actual:  AvgHR    158\n",
      "Name: 1, dtype: int64 \n",
      " pred:  [156.17487072] \n",
      "\n",
      "mse:  3.331096884140787\n",
      "Iteration:  9\n",
      "X train shape:  299\n",
      "X test shape:  1\n",
      "actual:  AvgHR    158\n",
      "Name: 0, dtype: int64 \n",
      " pred:  [157.26441077] \n",
      "\n",
      "mse:  0.541091522535688\n",
      "actuals and preds: \n",
      "    Predictions  Actuals\n",
      "0   155.565091      158\n",
      "1   155.634014      158\n",
      "2   149.418457      159\n",
      "3   155.821445      161\n",
      "4   158.765809      155\n",
      "5   154.297617      155\n",
      "6   158.404670      158\n",
      "7   156.345848      142\n",
      "8   156.174871      153\n",
      "9   157.264411      154\n",
      "mse for window size 10: 37.15280220103187\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "window_size = 10\n",
    "print('# Predictions: ', window_size)\n",
    "print('Window Size: ', 309-window_size)\n",
    "# train set\n",
    "X_train = X.iloc[window_size:]\n",
    "y_train = y.iloc[window_size:]\n",
    "print('train labels: ', y_train)\n",
    "# test set\n",
    "X_test = X.iloc[:window_size]\n",
    "y_test = y.iloc[:window_size]\n",
    "print('test labels: ', y_test)\n",
    "\n",
    "actuals = pd.DataFrame(y_test)\n",
    "actuals = actuals.rename(columns={'AvgHR':'Actuals'})\n",
    "# print('actuals: \\n', actuals)\n",
    "preds = np.zeros(X_test.shape[0])\n",
    "# print('X_test: \\n', X_test)\n",
    "\n",
    "for i in range(0,y_test.shape[0]):\n",
    "    print('Iteration: ', i)\n",
    "    print('X train shape: ', X_train.shape[0])\n",
    "    print('X test shape: ', y_test.shape[0])\n",
    "    # Fit model\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    # Predict test set\n",
    "    y_pred = clf.predict(np.array(X_test.iloc[-1]).reshape(1,-1))\n",
    "    # Compute mean squared error\n",
    "    mse = mean_squared_error(y_test.iloc[-1], y_pred)\n",
    "    print('actual: ',y_test.iloc[-1], '\\n pred: ',y_pred, '\\n')\n",
    "    preds[i] = y_pred\n",
    "    print('mse: ', mse)\n",
    "    # print('Accuracy of logistic regression classifier on test set {}: {:.2f}'.format(i, logreg.score(X_test, y_test)))\n",
    "    #print('test instance: ', X_test.iloc[-1])\n",
    "    # X_train = pd.concat([X_test.iloc[0], X_train]).reset_index(drop = True)\n",
    "    # print('new X train: ', X_train.head())\n",
    "    \n",
    "    # Perform LOO cross-validation\n",
    "    #print(\"X test -1: \", X_test.iloc[-1])\n",
    "    X_test_inst = pd.DataFrame(data= [X_test.iloc[-1]],columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "    y_test_inst = pd.DataFrame(data = [y_test.iloc[-1]],columns=[\"AvgHR\"])\n",
    "    #print(\"X test inst: \", X_test_inst)\n",
    "    X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "    X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "    #print(\"X train: \\n\", X_train)\n",
    "\n",
    "    y_train = y_train.drop(y_train.index[-1])\n",
    "    y_train = pd.concat([y_test_inst,y_train])\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    #print(\"y train \\n\", y_train)\n",
    "    \n",
    "    X_test = X_test.drop(X_test.index[-1])\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    #print(\"X test: \\n\", X_test)\n",
    "\n",
    "    y_test = y_test.drop(y_test.index[-1])\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "preds_act_df = pd.DataFrame(preds, columns=['Predictions'])\n",
    "preds_act_df = preds_act_df.join(actuals)\n",
    "print('actuals and preds: \\n', preds_act_df)\n",
    "final_mse = metrics.mean_squared_error(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "print('mse for window size {}: {}'.format(window_size, final_mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Over All Window Sizes for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all window sizes to determine optimal size\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Change window_size_optimization flag to perform iterations\n",
    "window_size_optimization = False\n",
    "\n",
    "if window_size_optimization == True:\n",
    "\n",
    "    # Fit regression model\n",
    "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    \n",
    "    accuracies = np.zeros(276)\n",
    "    mses = np.zeros(276)\n",
    "    #298 accuracy indices\n",
    "\n",
    "    # Iterate over all window sizes and compute accuracy for each LR model\n",
    "    for window_size in range(1,277):\n",
    "    #window_size = 299\n",
    "        print('# Predictions: ', window_size)\n",
    "        X_train = X.iloc[window_size:]\n",
    "        y_train = y.iloc[window_size:]\n",
    "        # print('train labels: ', y_train)\n",
    "        X_test = X.iloc[:window_size]\n",
    "        y_test = y.iloc[:window_size]\n",
    "        # print('test labels: ', y_test)\n",
    "\n",
    "        actuals = pd.DataFrame(y_test)\n",
    "        actuals = actuals.rename(columns={'AvgHR':'Actuals'})\n",
    "        # print('actuals: \\n', actuals)\n",
    "        preds = np.zeros(X_test.shape[0])\n",
    "        # print('X_test: \\n', X_test)\n",
    "        for i in range(0,y_test.shape[0]):\n",
    "            # Fit model\n",
    "            clf.fit(X_train, y_train.values.ravel())\n",
    "            # Predict test set\n",
    "            y_pred = clf.predict(np.array(X_test.iloc[-1]).reshape(1,-1))\n",
    "            preds[i] = y_pred\n",
    "            # Compute mean squared error\n",
    "            mse = mean_squared_error(y_test.iloc[-1], y_pred)\n",
    "            #print('Accuracy of logistic regression classifier on test set {}: {:.2f}'.format(i, logreg.score(X_test, y_test)))\n",
    "            #print(\"X test -1: \", X_test.iloc[-1])\n",
    "            \n",
    "            # Perform LOO cross-validation and add window of test instances to X_train, y_train\n",
    "            X_test_inst = pd.DataFrame(data= [X_test.iloc[-1]],columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "            y_test_inst = pd.DataFrame(data = [y_test.iloc[-1]],columns=[\"AvgHR\"])\n",
    "            #print(\"X test inst: \", X_test_inst)\n",
    "            X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "            X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "            #print(\"X train: \\n\", X_train)\n",
    "\n",
    "            y_train = y_train.drop(y_train.index[-1])\n",
    "            y_train = pd.concat([y_test_inst,y_train])\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "            #print(\"y train \\n\", y_train)\n",
    "\n",
    "            X_test = X_test.drop(X_test.index[-1])\n",
    "            X_test = X_test.reset_index(drop=True)\n",
    "            #print(\"X test: \\n\", X_test)\n",
    "            y_test = y_test.drop(y_test.index[-1])\n",
    "            y_test = y_test.reset_index(drop=True)\n",
    "            \n",
    "        preds_act_df = pd.DataFrame(preds, columns=['Predictions'])\n",
    "        preds_act_df = preds_act_df.join(actuals)\n",
    "        # print('actuals and preds: \\n', preds_act_df)\n",
    "        #accuracy = metrics.accuracy_score(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "        mse_final = metrics.mean_squared_error(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "        print('mse for window size {}: {}'.format(309-window_size, mse_final))\n",
    "        #accuracies[window_size-1] = accuracy\n",
    "        mses[window_size-1] = mse_final\n",
    "    #print('Accuracies: ', accuracies)\n",
    "    print('mses: ', mses)\n",
    "    # Output accuracies for each window size to Accuracies_for_Window_Size_Variations.csv file \n",
    "    with open('GB_Accuracies_for_Window_Size_Variations.csv', 'w') as f:\n",
    "        for i in range(0,len(mses)):\n",
    "            f.write(str(308-i) + ': ' + str(mses[i]))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GB_Accuracies_for_Window_Size_Variations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-44c649816e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Window'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GB_Accuracies_for_Window_Size_Variations.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmylist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Window'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GB_Accuracies_for_Window_Size_Variations.csv'"
     ]
    }
   ],
   "source": [
    "# Read in accuracies for each window size from Accuracies_for_Window_Size_Variations.csv file and sort by accuracy to determine best window size\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "mylist = pd.DataFrame(columns=['Window', 'Accuracy'])\n",
    "with open('GB_Accuracies_for_Window_Size_Variations.csv', 'r') as csvfile:\n",
    "    for i,row in enumerate(csv.reader(csvfile, delimiter='\\n')):\n",
    "        mylist.loc[i,'Window'] = row[0].split(':')[0]\n",
    "        mylist.loc[i,'Accuracy'] = float(row[0].split(':')[1])\n",
    "print(mylist.sort_values('Accuracy', 0,ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Over All Look Ahead Values for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  7\n",
      "Window Size:  302\n",
      "\n",
      "\n",
      "look ahead:  1\n",
      "# iterations:  7\n",
      "predictions:  [155.73537003]\n",
      "actuals:  [158.]\n",
      "predictions:  [158.73157508]\n",
      "actuals:  [155.]\n",
      "predictions:  [154.38306507]\n",
      "actuals:  [155.]\n",
      "predictions:  [158.2766407]\n",
      "actuals:  [161.]\n",
      "predictions:  [155.8541708]\n",
      "actuals:  [159.]\n",
      "predictions:  [156.62636066]\n",
      "actuals:  [158.]\n",
      "predictions:  [157.00438902]\n",
      "actuals:  [158.]\n",
      "mses:  [ 5.12854891 13.92465258  0.38060871  7.41668588  9.89624138  1.88688502\n",
      "  0.99124123]\n",
      "avg mse:  5.660694816497746\n",
      "\n",
      "\n",
      "look ahead:  2\n",
      "# iterations:  4\n",
      "predictions:  [155.73537003 159.13374524]\n",
      "actuals:  [158. 155.]\n",
      "predictions:  [154.38306507 158.49671894]\n",
      "actuals:  [155. 161.]\n",
      "predictions:  [155.8541708  156.59086728]\n",
      "actuals:  [159. 158.]\n",
      "predictions:  [157.00438902]\n",
      "actuals:  [158.]\n",
      "mses:  [11.10819931  3.32351239  5.9409482   0.99124123]\n",
      "avg mse:  5.340975282637976\n",
      "\n",
      "\n",
      "look ahead:  3\n",
      "# iterations:  3\n",
      "predictions:  [155.73537003 159.13374524 154.35583219]\n",
      "actuals:  [158. 155. 155.]\n",
      "predictions:  [158.2766407  155.95116188 156.57741876]\n",
      "actuals:  [161. 159. 158.]\n",
      "predictions:  [156.98652378]\n",
      "actuals:  [158.]\n",
      "mses:  [7.5437836  6.24527905 1.02713406]\n",
      "avg mse:  4.938732233988211\n",
      "\n",
      "\n",
      "look ahead:  4\n",
      "# iterations:  2\n",
      "predictions:  [155.73537003 159.13374524 154.37012012 158.47257613]\n",
      "actuals:  [158. 155. 155. 161.]\n",
      "predictions:  [155.8541708  156.59086728 156.33146642]\n",
      "actuals:  [159. 158. 158.]\n",
      "mses:  [7.25025468 4.88863357]\n",
      "avg mse:  6.069444124087017\n",
      "\n",
      "\n",
      "look ahead:  5\n",
      "# iterations:  2\n",
      "predictions:  [155.73537003 159.13374524 154.37012012 158.47257613 155.96239067]\n",
      "actuals:  [158. 155. 155. 161. 159.]\n",
      "predictions:  [156.66860812 156.94894694]\n",
      "actuals:  [158. 158.]\n",
      "mses:  [7.64561784 1.43865843]\n",
      "avg mse:  4.542138133048171\n",
      "\n",
      "\n",
      "look ahead:  6\n",
      "# iterations:  2\n",
      "predictions:  [155.73537003 159.13374524 154.34139994 158.47257613 155.96239067\n",
      " 157.23838912]\n",
      "actuals:  [158. 155. 155. 161. 159. 158.]\n",
      "predictions:  [157.00354863]\n",
      "actuals:  [158.]\n",
      "mses:  [6.47419095 0.99291534]\n",
      "avg mse:  3.7335531445110477\n",
      "\n",
      "\n",
      "look ahead:  7\n",
      "# iterations:  1\n",
      "predictions:  [155.73537003 159.13374524 154.35568787 158.47257613 155.96239067\n",
      " 157.09093603 159.47246694]\n",
      "actuals:  [158. 155. 155. 161. 159. 158. 158.]\n",
      "mses:  [5.8915764]\n",
      "avg mse:  5.891576402507408\n",
      "Averages:      Avg MSE\n",
      "0  5.660695\n",
      "1  5.340975\n",
      "2  4.938732\n",
      "3  6.069444\n",
      "4  4.542138\n",
      "5  3.733553\n",
      "6  5.891576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import statistics as stats\n",
    "# Run GB with optimal window size of 302 (# predictions = 7) for all look ahead values from 1 to 7\n",
    "\n",
    "window_size = 7 # num of preds, window_size = 309-window_size param\n",
    "print('# Predictions: ', window_size)\n",
    "print('Window Size: ', 309-window_size)\n",
    "avg_mses = np.zeros(window_size)\n",
    "\n",
    "for m in range(1,window_size+1):\n",
    "    # train set\n",
    "    X_train = X.iloc[window_size:]\n",
    "    y_train = y.iloc[window_size:]\n",
    "    #print('train labels: ', y_train)\n",
    "    # test set\n",
    "    X_test = X.iloc[:window_size]\n",
    "    y_test = y.iloc[:window_size]\n",
    "    #print('test labels: ', y_test)\n",
    "    \n",
    "    #look_ahead = 7\n",
    "    look_ahead=m\n",
    "    print(\"\\n\\nlook ahead: \", m)\n",
    "    print(\"# iterations: \", math.ceil(y_test.shape[0]/look_ahead))\n",
    "    \n",
    "    mses = np.zeros(math.ceil(y_test.shape[0]/look_ahead))\n",
    "\n",
    "    for i in range(0,math.ceil(y_test.shape[0]/look_ahead)):\n",
    "        preds = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "        actuals_look_ahead = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "        # print('Iteration: ', i)\n",
    "        # print('X train shape: ', X_train.shape[0])\n",
    "        # print('X test shape: ', y_test.shape[0])\n",
    "        # Fit model\n",
    "        clf.fit(X_train, y_train.values.ravel())\n",
    "        # Predict test set\n",
    "        for j in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "            y_pred = clf.predict(np.array(X_test.iloc[-j]).reshape(1,-1))\n",
    "            # print('actual: ',y_test.iloc[-j], '\\n pred: ',y_pred, '\\n')\n",
    "            preds[j-1] = y_pred\n",
    "            actuals_look_ahead[j-1] = y_test.iloc[-j]\n",
    "        \n",
    "        # Perform cross-validation and add window of test instances to X_train, y_train\n",
    "        #print(\"X test -1: \", X_test.iloc[-1])\n",
    "        X_test_inst = pd.DataFrame(columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "        y_test_inst = pd.DataFrame(columns=[\"AvgHR\"])\n",
    "        for k in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "            X_test_inst = X_test_inst.append(X_test.iloc[-k])\n",
    "            y_test_inst = y_test_inst.append(y_test.iloc[-k])        \n",
    "        #print(\"X test inst: \", X_test_inst)\n",
    "\n",
    "        #X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "        X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "        #print(\"X train: \\n\", X_train)\n",
    "\n",
    "        #y_train = y_train.drop(y_train.index[-1])\n",
    "        y_train = pd.concat([y_test_inst,y_train]).reset_index(drop=True)\n",
    "        #print(\"y train \\n\", y_train)\n",
    "\n",
    "        X_test = X_test.drop(X_test_inst.index.values)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        #print(\"X test: \\n\", X_test)\n",
    "\n",
    "        y_test = y_test.drop(y_test_inst.index.values)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        preds_act_df = pd.DataFrame(preds)\n",
    "        act_df = pd.DataFrame(actuals_look_ahead)\n",
    "        print(\"predictions: \", preds)\n",
    "        print(\"actuals: \", actuals_look_ahead)\n",
    "     \n",
    "        # Compute mean squared error\n",
    "        mse = metrics.mean_squared_error(preds,actuals_look_ahead)\n",
    "    \n",
    "        mses[i] = mse\n",
    "    \n",
    "    print('mses: ', mses)\n",
    "    avg_mse = stats.mean(mses)\n",
    "    print('avg mse: ', avg_mse)\n",
    "    avg_mses[m-1] = avg_mse\n",
    "\n",
    "avg_acc_df = pd.DataFrame(data=avg_mses, columns=['Avg MSE'])\n",
    "print('Averages: ', avg_acc_df) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB with Optimal Window Size = 302 and Look Ahead = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  7\n",
      "Window Size:  302\n",
      "train labels:       AvgHR\n",
      "7      142\n",
      "8      153\n",
      "9      154\n",
      "10     168\n",
      "11     165\n",
      "12     166\n",
      "13     151\n",
      "14     162\n",
      "15     136\n",
      "16     150\n",
      "17     165\n",
      "18     150\n",
      "19     158\n",
      "20     161\n",
      "21     141\n",
      "22     142\n",
      "23     149\n",
      "24     142\n",
      "25     145\n",
      "26     140\n",
      "27     126\n",
      "28     142\n",
      "29     137\n",
      "30     146\n",
      "31     150\n",
      "32     154\n",
      "33     139\n",
      "34     141\n",
      "35     148\n",
      "36     145\n",
      "37     132\n",
      "38     143\n",
      "39     141\n",
      "40     138\n",
      "41     142\n",
      "42     149\n",
      "43     148\n",
      "44     145\n",
      "45     148\n",
      "46     142\n",
      "47     133\n",
      "48     143\n",
      "49     141\n",
      "50     141\n",
      "51     144\n",
      "52     167\n",
      "53     157\n",
      "54     147\n",
      "55     147\n",
      "56     154\n",
      "57     153\n",
      "58     145\n",
      "59     152\n",
      "60     140\n",
      "61     154\n",
      "62     142\n",
      "63     145\n",
      "64     153\n",
      "65     161\n",
      "66     149\n",
      "67      84\n",
      "68     168\n",
      "69     148\n",
      "70     145\n",
      "71     175\n",
      "72     155\n",
      "73     166\n",
      "74     143\n",
      "75     146\n",
      "76     164\n",
      "77     152\n",
      "78     155\n",
      "79     152\n",
      "80     186\n",
      "81     147\n",
      "82     143\n",
      "83     151\n",
      "84     157\n",
      "85     157\n",
      "86     156\n",
      "87     155\n",
      "88     168\n",
      "89     154\n",
      "90     175\n",
      "91     155\n",
      "92     167\n",
      "93     186\n",
      "94     163\n",
      "95     170\n",
      "96     168\n",
      "97     147\n",
      "98     164\n",
      "99     187\n",
      "100    185\n",
      "101    178\n",
      "102    170\n",
      "103    188\n",
      "104    134\n",
      "105    159\n",
      "106    150\n",
      "107    149\n",
      "108    188\n",
      "109    177\n",
      "110    159\n",
      "111    185\n",
      "112    171\n",
      "113    189\n",
      "114    178\n",
      "115    169\n",
      "116    170\n",
      "117    155\n",
      "118    167\n",
      "119    191\n",
      "120    165\n",
      "121    173\n",
      "122    161\n",
      "123    151\n",
      "124    149\n",
      "125    154\n",
      "126    163\n",
      "127    151\n",
      "128    176\n",
      "129    157\n",
      "130    176\n",
      "131    138\n",
      "132    184\n",
      "133    138\n",
      "134    175\n",
      "135    164\n",
      "136    137\n",
      "137    156\n",
      "138    165\n",
      "139    178\n",
      "140    155\n",
      "141    156\n",
      "142    144\n",
      "143    167\n",
      "144    165\n",
      "145    154\n",
      "146    190\n",
      "147    174\n",
      "148    166\n",
      "149    191\n",
      "150    156\n",
      "151    154\n",
      "152    151\n",
      "153    155\n",
      "154    154\n",
      "155    156\n",
      "156    155\n",
      "157    161\n",
      "158    142\n",
      "159    154\n",
      "160    163\n",
      "161    162\n",
      "162    162\n",
      "163    135\n",
      "164    159\n",
      "165    158\n",
      "166    149\n",
      "167    164\n",
      "168    159\n",
      "169    153\n",
      "170    152\n",
      "171    155\n",
      "172    164\n",
      "173    161\n",
      "174    159\n",
      "175    168\n",
      "176    157\n",
      "177    153\n",
      "178    151\n",
      "179    134\n",
      "180    156\n",
      "181    163\n",
      "182    154\n",
      "183    158\n",
      "184    162\n",
      "185    153\n",
      "186    156\n",
      "187    171\n",
      "188    167\n",
      "189    150\n",
      "190    160\n",
      "191    159\n",
      "192    152\n",
      "193    166\n",
      "194    156\n",
      "195    157\n",
      "196    168\n",
      "197    138\n",
      "198    156\n",
      "199    153\n",
      "200    153\n",
      "201    164\n",
      "202    149\n",
      "203    161\n",
      "204    155\n",
      "205    146\n",
      "206    158\n",
      "207    156\n",
      "208    161\n",
      "209    118\n",
      "210    143\n",
      "211    160\n",
      "212    159\n",
      "213    155\n",
      "214    161\n",
      "215    149\n",
      "216    155\n",
      "217    157\n",
      "218    155\n",
      "219    167\n",
      "220    155\n",
      "221    161\n",
      "222    157\n",
      "223    157\n",
      "224    156\n",
      "225    161\n",
      "226    151\n",
      "227    155\n",
      "228    163\n",
      "229    158\n",
      "230    156\n",
      "231    146\n",
      "232    154\n",
      "233    151\n",
      "234    158\n",
      "235    164\n",
      "236    163\n",
      "237    160\n",
      "238    161\n",
      "239    159\n",
      "240    166\n",
      "241    165\n",
      "242    142\n",
      "243    161\n",
      "244    153\n",
      "245    152\n",
      "246    155\n",
      "247    156\n",
      "248    133\n",
      "249    152\n",
      "250    145\n",
      "251    160\n",
      "252    156\n",
      "253    157\n",
      "254    133\n",
      "255    154\n",
      "256    154\n",
      "257    155\n",
      "258    160\n",
      "259    147\n",
      "260    155\n",
      "261    155\n",
      "262    147\n",
      "263    157\n",
      "264    149\n",
      "265    160\n",
      "266    148\n",
      "267    148\n",
      "268    150\n",
      "269    145\n",
      "270    155\n",
      "271    140\n",
      "272    149\n",
      "273    151\n",
      "274    150\n",
      "275    152\n",
      "276    156\n",
      "277    150\n",
      "278    174\n",
      "279    153\n",
      "280    152\n",
      "281    153\n",
      "282    130\n",
      "283    155\n",
      "284    156\n",
      "285    157\n",
      "286    151\n",
      "287    157\n",
      "288    149\n",
      "289    126\n",
      "290    154\n",
      "291    160\n",
      "292    156\n",
      "293    147\n",
      "294    145\n",
      "295    155\n",
      "296    154\n",
      "297    151\n",
      "298    156\n",
      "299    153\n",
      "300    129\n",
      "301    154\n",
      "302    149\n",
      "303    126\n",
      "304    149\n",
      "305    148\n",
      "306    150\n",
      "307    131\n",
      "308    151\n",
      "test labels:     AvgHR\n",
      "0    158\n",
      "1    158\n",
      "2    159\n",
      "3    161\n",
      "4    155\n",
      "5    155\n",
      "6    158\n",
      "Iteration:  0\n",
      "X train shape:  302\n",
      "X test shape:  7\n",
      "actual:  AvgHR    158\n",
      "Name: 6, dtype: int64 \n",
      " pred:  [155.73537003] \n",
      "\n",
      "actual:  AvgHR    155\n",
      "Name: 5, dtype: int64 \n",
      " pred:  [159.13374524] \n",
      "\n",
      "actual:  AvgHR    155\n",
      "Name: 4, dtype: int64 \n",
      " pred:  [154.35583219] \n",
      "\n",
      "actual:  AvgHR    161\n",
      "Name: 3, dtype: int64 \n",
      " pred:  [158.47257613] \n",
      "\n",
      "actual:  AvgHR    159\n",
      "Name: 2, dtype: int64 \n",
      " pred:  [155.96239067] \n",
      "\n",
      "X test inst:     Distance (km)  Avg Pace (/km)   HRSS  Elevation Gain (m)\n",
      "6           81.0           129.0  225.0              1096.0\n",
      "5           61.4           122.0  146.0               692.0\n",
      "4           41.1           120.0   96.0               454.0\n",
      "3           45.6           114.0  119.0               447.0\n",
      "2           35.2           116.0   87.0               314.0\n",
      "predictions:  [155.73537003 159.13374524 154.35583219 158.47257613 155.96239067]\n",
      "actuals:  [158. 155. 155. 161. 159.]\n",
      "mse for window size 302 with look ahead value 5: 7.649258537221293\n",
      "Iteration:  1\n",
      "X train shape:  307\n",
      "X test shape:  2\n",
      "actual:  AvgHR    158\n",
      "Name: 1, dtype: int64 \n",
      " pred:  [156.66860812] \n",
      "\n",
      "actual:  AvgHR    158\n",
      "Name: 0, dtype: int64 \n",
      " pred:  [156.94894694] \n",
      "\n",
      "X test inst:     Distance (km)  Avg Pace (/km)   HRSS  Elevation Gain (m)\n",
      "1           80.1           125.0  217.0               890.0\n",
      "0           62.5           113.0  144.0               589.0\n",
      "predictions:  [156.66860812 156.94894694]\n",
      "actuals:  [158. 158.]\n",
      "mse for window size 302 with look ahead value 5: 1.4386584299441507\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import statistics as stats\n",
    "# Run GB with optimal window size of 302 (# predictions = 7) and optimal look ahead = 5\n",
    "\n",
    "window_size = 7 # num of preds, window_size = 309-window_size param\n",
    "print('# Predictions: ', window_size)\n",
    "print('Window Size: ', 309-window_size)\n",
    "# train set\n",
    "X_train = X.iloc[window_size:]\n",
    "y_train = y.iloc[window_size:]\n",
    "print('train labels: ', y_train)\n",
    "# test set\n",
    "X_test = X.iloc[:window_size]\n",
    "y_test = y.iloc[:window_size]\n",
    "print('test labels: ', y_test)\n",
    "\n",
    "look_ahead = 5\n",
    "\n",
    "mses = np.zeros(math.ceil(y_test.shape[0]/look_ahead))\n",
    "\n",
    "# print('X_test: \\n', X_test)\n",
    "\n",
    "for i in range(0,math.ceil(y_test.shape[0]/look_ahead)):\n",
    "    preds = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "    actuals_look_ahead = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "    print('Iteration: ', i)\n",
    "    print('X train shape: ', X_train.shape[0])\n",
    "    print('X test shape: ', y_test.shape[0])\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    # Predict test set\n",
    "    for j in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "        y_pred = clf.predict(np.array(X_test.iloc[-j]).reshape(1,-1))\n",
    "        print('actual: ',y_test.iloc[-j], '\\n pred: ',y_pred, '\\n')\n",
    "        preds[j-1] = y_pred\n",
    "        actuals_look_ahead[j-1] = y_test.iloc[-j]\n",
    "    # print('Accuracy of logistic regression classifier on test set {}: {:.2f}'.format(i, logreg.score(X_test, y_test)))\n",
    "    #print('test instance: ', X_test.iloc[-1])\n",
    "    # X_train = pd.concat([X_test.iloc[0], X_train]).reset_index(drop = True)\n",
    "    # print('new X train: ', X_train.head())\n",
    "    \n",
    "    #print(\"X test -1: \", X_test.iloc[-1])\n",
    "    X_test_inst = pd.DataFrame(columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "    y_test_inst = pd.DataFrame(columns=[\"AvgHR\"])\n",
    "    for k in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "        X_test_inst = X_test_inst.append(X_test.iloc[-k])\n",
    "        y_test_inst = y_test_inst.append(y_test.iloc[-k])        \n",
    "    print(\"X test inst: \", X_test_inst)\n",
    "\n",
    "    #X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "    X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "    #print(\"X train: \\n\", X_train)\n",
    "\n",
    "    #y_train = y_train.drop(y_train.index[-1])\n",
    "    y_train = pd.concat([y_test_inst,y_train]).reset_index(drop=True)\n",
    "    #print(\"y train \\n\", y_train)\n",
    "    \n",
    "    X_test = X_test.drop(X_test_inst.index.values)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    #print(\"X test: \\n\", X_test)\n",
    "\n",
    "    y_test = y_test.drop(y_test_inst.index.values)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    preds_act_df = pd.DataFrame(preds)\n",
    "    act_df = pd.DataFrame(actuals_look_ahead)\n",
    "    print(\"predictions: \", preds)\n",
    "    print(\"actuals: \", actuals_look_ahead)\n",
    "    #preds_act_df = preds_act_df.join(act_df)\n",
    "    #print('actuals and preds: \\n', preds_act_df)\n",
    "    mse = metrics.mean_squared_error(preds,actuals_look_ahead)\n",
    "    mses[i] = mse\n",
    "    print('mse for window size {} with look ahead value {}: {}'.format(309-window_size, look_ahead, mse))\n",
    "    \n",
    "#print('accuracies: ', accuracies)\n",
    "#print('avg accuracy: ', stats.mean(accuracies))\n",
    "# preds_act_df = pd.DataFrame(preds)\n",
    "# preds_act_df = preds_act_df.join(actuals)\n",
    "# print('actuals and preds: \\n', preds_act_df)\n",
    "# accuracy = metrics.accuracy_score(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "# print('accuracy for window size {}: {}'.format(window_size, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  7\n",
      "Window Size:  302\n",
      "train labels:       AvgHR\n",
      "7      142\n",
      "8      153\n",
      "9      154\n",
      "10     168\n",
      "11     165\n",
      "12     166\n",
      "13     151\n",
      "14     162\n",
      "15     136\n",
      "16     150\n",
      "17     165\n",
      "18     150\n",
      "19     158\n",
      "20     161\n",
      "21     141\n",
      "22     142\n",
      "23     149\n",
      "24     142\n",
      "25     145\n",
      "26     140\n",
      "27     126\n",
      "28     142\n",
      "29     137\n",
      "30     146\n",
      "31     150\n",
      "32     154\n",
      "33     139\n",
      "34     141\n",
      "35     148\n",
      "36     145\n",
      "37     132\n",
      "38     143\n",
      "39     141\n",
      "40     138\n",
      "41     142\n",
      "42     149\n",
      "43     148\n",
      "44     145\n",
      "45     148\n",
      "46     142\n",
      "47     133\n",
      "48     143\n",
      "49     141\n",
      "50     141\n",
      "51     144\n",
      "52     167\n",
      "53     157\n",
      "54     147\n",
      "55     147\n",
      "56     154\n",
      "57     153\n",
      "58     145\n",
      "59     152\n",
      "60     140\n",
      "61     154\n",
      "62     142\n",
      "63     145\n",
      "64     153\n",
      "65     161\n",
      "66     149\n",
      "67      84\n",
      "68     168\n",
      "69     148\n",
      "70     145\n",
      "71     175\n",
      "72     155\n",
      "73     166\n",
      "74     143\n",
      "75     146\n",
      "76     164\n",
      "77     152\n",
      "78     155\n",
      "79     152\n",
      "80     186\n",
      "81     147\n",
      "82     143\n",
      "83     151\n",
      "84     157\n",
      "85     157\n",
      "86     156\n",
      "87     155\n",
      "88     168\n",
      "89     154\n",
      "90     175\n",
      "91     155\n",
      "92     167\n",
      "93     186\n",
      "94     163\n",
      "95     170\n",
      "96     168\n",
      "97     147\n",
      "98     164\n",
      "99     187\n",
      "100    185\n",
      "101    178\n",
      "102    170\n",
      "103    188\n",
      "104    134\n",
      "105    159\n",
      "106    150\n",
      "107    149\n",
      "108    188\n",
      "109    177\n",
      "110    159\n",
      "111    185\n",
      "112    171\n",
      "113    189\n",
      "114    178\n",
      "115    169\n",
      "116    170\n",
      "117    155\n",
      "118    167\n",
      "119    191\n",
      "120    165\n",
      "121    173\n",
      "122    161\n",
      "123    151\n",
      "124    149\n",
      "125    154\n",
      "126    163\n",
      "127    151\n",
      "128    176\n",
      "129    157\n",
      "130    176\n",
      "131    138\n",
      "132    184\n",
      "133    138\n",
      "134    175\n",
      "135    164\n",
      "136    137\n",
      "137    156\n",
      "138    165\n",
      "139    178\n",
      "140    155\n",
      "141    156\n",
      "142    144\n",
      "143    167\n",
      "144    165\n",
      "145    154\n",
      "146    190\n",
      "147    174\n",
      "148    166\n",
      "149    191\n",
      "150    156\n",
      "151    154\n",
      "152    151\n",
      "153    155\n",
      "154    154\n",
      "155    156\n",
      "156    155\n",
      "157    161\n",
      "158    142\n",
      "159    154\n",
      "160    163\n",
      "161    162\n",
      "162    162\n",
      "163    135\n",
      "164    159\n",
      "165    158\n",
      "166    149\n",
      "167    164\n",
      "168    159\n",
      "169    153\n",
      "170    152\n",
      "171    155\n",
      "172    164\n",
      "173    161\n",
      "174    159\n",
      "175    168\n",
      "176    157\n",
      "177    153\n",
      "178    151\n",
      "179    134\n",
      "180    156\n",
      "181    163\n",
      "182    154\n",
      "183    158\n",
      "184    162\n",
      "185    153\n",
      "186    156\n",
      "187    171\n",
      "188    167\n",
      "189    150\n",
      "190    160\n",
      "191    159\n",
      "192    152\n",
      "193    166\n",
      "194    156\n",
      "195    157\n",
      "196    168\n",
      "197    138\n",
      "198    156\n",
      "199    153\n",
      "200    153\n",
      "201    164\n",
      "202    149\n",
      "203    161\n",
      "204    155\n",
      "205    146\n",
      "206    158\n",
      "207    156\n",
      "208    161\n",
      "209    118\n",
      "210    143\n",
      "211    160\n",
      "212    159\n",
      "213    155\n",
      "214    161\n",
      "215    149\n",
      "216    155\n",
      "217    157\n",
      "218    155\n",
      "219    167\n",
      "220    155\n",
      "221    161\n",
      "222    157\n",
      "223    157\n",
      "224    156\n",
      "225    161\n",
      "226    151\n",
      "227    155\n",
      "228    163\n",
      "229    158\n",
      "230    156\n",
      "231    146\n",
      "232    154\n",
      "233    151\n",
      "234    158\n",
      "235    164\n",
      "236    163\n",
      "237    160\n",
      "238    161\n",
      "239    159\n",
      "240    166\n",
      "241    165\n",
      "242    142\n",
      "243    161\n",
      "244    153\n",
      "245    152\n",
      "246    155\n",
      "247    156\n",
      "248    133\n",
      "249    152\n",
      "250    145\n",
      "251    160\n",
      "252    156\n",
      "253    157\n",
      "254    133\n",
      "255    154\n",
      "256    154\n",
      "257    155\n",
      "258    160\n",
      "259    147\n",
      "260    155\n",
      "261    155\n",
      "262    147\n",
      "263    157\n",
      "264    149\n",
      "265    160\n",
      "266    148\n",
      "267    148\n",
      "268    150\n",
      "269    145\n",
      "270    155\n",
      "271    140\n",
      "272    149\n",
      "273    151\n",
      "274    150\n",
      "275    152\n",
      "276    156\n",
      "277    150\n",
      "278    174\n",
      "279    153\n",
      "280    152\n",
      "281    153\n",
      "282    130\n",
      "283    155\n",
      "284    156\n",
      "285    157\n",
      "286    151\n",
      "287    157\n",
      "288    149\n",
      "289    126\n",
      "290    154\n",
      "291    160\n",
      "292    156\n",
      "293    147\n",
      "294    145\n",
      "295    155\n",
      "296    154\n",
      "297    151\n",
      "298    156\n",
      "299    153\n",
      "300    129\n",
      "301    154\n",
      "302    149\n",
      "303    126\n",
      "304    149\n",
      "305    148\n",
      "306    150\n",
      "307    131\n",
      "308    151\n",
      "test labels:     AvgHR\n",
      "0    158\n",
      "1    158\n",
      "2    159\n",
      "3    161\n",
      "4    155\n",
      "5    155\n",
      "6    158\n",
      "Iteration:  0\n",
      "X train shape:  302\n",
      "X test shape:  7\n",
      "actual:  AvgHR    158\n",
      "Name: 6, dtype: int64 \n",
      " pred:  [156.11] \n",
      "\n",
      "actual:  AvgHR    155\n",
      "Name: 5, dtype: int64 \n",
      " pred:  [158.74] \n",
      "\n",
      "actual:  AvgHR    155\n",
      "Name: 4, dtype: int64 \n",
      " pred:  [153.56] \n",
      "\n",
      "actual:  AvgHR    161\n",
      "Name: 3, dtype: int64 \n",
      " pred:  [158.31] \n",
      "\n",
      "actual:  AvgHR    159\n",
      "Name: 2, dtype: int64 \n",
      " pred:  [157.88] \n",
      "\n",
      "X test inst:     Distance (km)  Avg Pace (/km)   HRSS  Elevation Gain (m)\n",
      "6           81.0           129.0  225.0              1096.0\n",
      "5           61.4           122.0  146.0               692.0\n",
      "4           41.1           120.0   96.0               454.0\n",
      "3           45.6           114.0  119.0               447.0\n",
      "2           35.2           116.0   87.0               314.0\n",
      "predictions:  [156.11 158.74 153.56 158.31 157.88]\n",
      "actuals:  [158. 155. 155. 161. 159.]\n",
      "mse for window size 302 with look ahead value 5: 5.624760000000002\n",
      "Iteration:  1\n",
      "X train shape:  307\n",
      "X test shape:  2\n",
      "actual:  AvgHR    158\n",
      "Name: 1, dtype: int64 \n",
      " pred:  [157.48] \n",
      "\n",
      "actual:  AvgHR    158\n",
      "Name: 0, dtype: int64 \n",
      " pred:  [158.94] \n",
      "\n",
      "X test inst:     Distance (km)  Avg Pace (/km)   HRSS  Elevation Gain (m)\n",
      "1           80.1           125.0  217.0               890.0\n",
      "0           62.5           113.0  144.0               589.0\n",
      "predictions:  [157.48 158.94]\n",
      "actuals:  [158. 158.]\n",
      "mse for window size 302 with look ahead value 5: 0.5770000000000032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import statistics as stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Run GB with optimal window size of 302 (# predictions = 7) and optimal look ahead = 5\n",
    "\n",
    "window_size = 7 # num of preds, window_size = 309-window_size param\n",
    "print('# Predictions: ', window_size)\n",
    "print('Window Size: ', 309-window_size)\n",
    "# train set\n",
    "X_train = X.iloc[window_size:]\n",
    "y_train = y.iloc[window_size:]\n",
    "print('train labels: ', y_train)\n",
    "# test set\n",
    "X_test = X.iloc[:window_size]\n",
    "y_test = y.iloc[:window_size]\n",
    "print('test labels: ', y_test)\n",
    "\n",
    "look_ahead = 5\n",
    "\n",
    "mses = np.zeros(math.ceil(y_test.shape[0]/look_ahead))\n",
    "\n",
    "# print('X_test: \\n', X_test)\n",
    "\n",
    "for i in range(0,math.ceil(y_test.shape[0]/look_ahead)):\n",
    "    clf = RandomForestRegressor(n_estimators=100)\n",
    "    preds = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "    actuals_look_ahead = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "    print('Iteration: ', i)\n",
    "    print('X train shape: ', X_train.shape[0])\n",
    "    print('X test shape: ', y_test.shape[0])\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    # Predict test set\n",
    "    for j in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "        y_pred = clf.predict(np.array(X_test.iloc[-j]).reshape(1,-1))\n",
    "        print('actual: ',y_test.iloc[-j], '\\n pred: ',y_pred, '\\n')\n",
    "        preds[j-1] = y_pred\n",
    "        actuals_look_ahead[j-1] = y_test.iloc[-j]\n",
    "    # print('Accuracy of logistic regression classifier on test set {}: {:.2f}'.format(i, logreg.score(X_test, y_test)))\n",
    "    #print('test instance: ', X_test.iloc[-1])\n",
    "    # X_train = pd.concat([X_test.iloc[0], X_train]).reset_index(drop = True)\n",
    "    # print('new X train: ', X_train.head())\n",
    "    \n",
    "    #print(\"X test -1: \", X_test.iloc[-1])\n",
    "    X_test_inst = pd.DataFrame(columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "    y_test_inst = pd.DataFrame(columns=[\"AvgHR\"])\n",
    "    for k in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "        X_test_inst = X_test_inst.append(X_test.iloc[-k])\n",
    "        y_test_inst = y_test_inst.append(y_test.iloc[-k])        \n",
    "    print(\"X test inst: \", X_test_inst)\n",
    "\n",
    "    #X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "    X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "    #print(\"X train: \\n\", X_train)\n",
    "\n",
    "    #y_train = y_train.drop(y_train.index[-1])\n",
    "    y_train = pd.concat([y_test_inst,y_train]).reset_index(drop=True)\n",
    "    #print(\"y train \\n\", y_train)\n",
    "    \n",
    "    X_test = X_test.drop(X_test_inst.index.values)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    #print(\"X test: \\n\", X_test)\n",
    "\n",
    "    y_test = y_test.drop(y_test_inst.index.values)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    preds_act_df = pd.DataFrame(preds)\n",
    "    act_df = pd.DataFrame(actuals_look_ahead)\n",
    "    print(\"predictions: \", preds)\n",
    "    print(\"actuals: \", actuals_look_ahead)\n",
    "    preds_act_df = preds_act_df.join(actuals.iloc[::-1].reset_index(drop = True))\n",
    "    #preds_act_df = preds_act_df.join(act_df)\n",
    "    #print('actuals and preds: \\n', preds_act_df)\n",
    "    mse = metrics.mean_squared_error(preds,actuals_look_ahead)\n",
    "    mses[i] = mse\n",
    "    print('mse for window size {} with look ahead value {}: {}'.format(309-window_size, look_ahead, mse))\n",
    "    \n",
    "#print('accuracies: ', accuracies)\n",
    "#print('avg accuracy: ', stats.mean(accuracies))\n",
    "# preds_act_df = pd.DataFrame(preds)\n",
    "# preds_act_df = preds_act_df.join(actuals)\n",
    "# print('actuals and preds: \\n', preds_act_df)\n",
    "# accuracy = metrics.accuracy_score(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "# print('accuracy for window size {}: {}'.format(window_size, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  1\n",
      "mse for window size 308: 0.7056000000000058\n",
      "# Predictions:  2\n",
      "mse for window size 307: 0.6565000000000041\n",
      "# Predictions:  3\n",
      "mse for window size 306: 0.7718000000000127\n",
      "# Predictions:  4\n",
      "mse for window size 305: 3.276224999999991\n",
      "# Predictions:  5\n",
      "mse for window size 304: 10.921039999999953\n",
      "# Predictions:  6\n",
      "mse for window size 303: 8.490583333333324\n",
      "# Predictions:  7\n",
      "mse for window size 302: 8.062057142857139\n",
      "# Predictions:  8\n",
      "mse for window size 301: 63.78115\n",
      "# Predictions:  9\n",
      "mse for window size 300: 43.44895555555553\n",
      "# Predictions:  10\n",
      "mse for window size 299: 46.40897999999997\n",
      "# Predictions:  11\n",
      "mse for window size 298: 56.166672727272754\n",
      "# Predictions:  12\n",
      "mse for window size 297: 37.344533333333345\n",
      "# Predictions:  13\n",
      "mse for window size 296: 56.00380000000004\n",
      "# Predictions:  14\n",
      "mse for window size 295: 91.40362857142854\n",
      "# Predictions:  15\n",
      "mse for window size 294: 64.14515333333331\n",
      "# Predictions:  16\n",
      "mse for window size 293: 121.26184374999997\n",
      "# Predictions:  17\n",
      "mse for window size 292: 127.08213529411763\n",
      "# Predictions:  18\n",
      "mse for window size 291: 136.88522777777777\n",
      "# Predictions:  19\n",
      "mse for window size 290: 143.82300526315785\n",
      "# Predictions:  20\n",
      "mse for window size 289: 126.94224999999997\n",
      "# Predictions:  21\n",
      "mse for window size 288: 64.38540952380954\n",
      "# Predictions:  22\n",
      "mse for window size 287: 128.19337727272736\n",
      "# Predictions:  23\n",
      "mse for window size 286: 73.74692608695656\n",
      "# Predictions:  24\n",
      "mse for window size 285: 119.52341250000006\n",
      "# Predictions:  25\n",
      "mse for window size 284: 172.169656\n",
      "# Predictions:  26\n",
      "mse for window size 283: 190.32449615384618\n",
      "# Predictions:  27\n",
      "mse for window size 282: 190.47737407407405\n",
      "# Predictions:  28\n",
      "mse for window size 281: 249.53916071428566\n",
      "# Predictions:  29\n",
      "mse for window size 280: 168.53487241379304\n",
      "# Predictions:  30\n",
      "mse for window size 279: 177.7233766666667\n",
      "# Predictions:  31\n",
      "mse for window size 278: 199.91672258064506\n",
      "# Predictions:  32\n",
      "mse for window size 277: 157.92517812500003\n",
      "# Predictions:  33\n",
      "mse for window size 276: 231.09201515151517\n",
      "# Predictions:  34\n",
      "mse for window size 275: 215.28378823529408\n",
      "# Predictions:  35\n",
      "mse for window size 274: 195.27602285714283\n",
      "# Predictions:  36\n",
      "mse for window size 273: 221.1079805555555\n",
      "# Predictions:  37\n",
      "mse for window size 272: 192.51491689189183\n",
      "# Predictions:  38\n",
      "mse for window size 271: 191.81672105263155\n",
      "# Predictions:  39\n",
      "mse for window size 270: 235.14686861538465\n",
      "# Predictions:  40\n",
      "mse for window size 269: 209.06813249999996\n",
      "# Predictions:  41\n",
      "mse for window size 268: 189.45324390243897\n",
      "# Predictions:  42\n",
      "mse for window size 267: 211.33112501653437\n",
      "# Predictions:  43\n",
      "mse for window size 266: 173.86708604651162\n",
      "# Predictions:  44\n",
      "mse for window size 265: 198.2417664772728\n",
      "# Predictions:  45\n",
      "mse for window size 264: 200.58127777777784\n",
      "# Predictions:  46\n",
      "mse for window size 263: 195.72231521739127\n",
      "# Predictions:  47\n",
      "mse for window size 262: 200.6495468953538\n",
      "# Predictions:  48\n",
      "mse for window size 261: 207.16734166666666\n",
      "# Predictions:  49\n",
      "mse for window size 260: 181.45819733560097\n",
      "# Predictions:  50\n",
      "mse for window size 259: 183.34136955555553\n",
      "# Predictions:  51\n",
      "mse for window size 258: 174.69412596078436\n",
      "# Predictions:  52\n",
      "mse for window size 257: 177.0892427884616\n",
      "# Predictions:  53\n",
      "mse for window size 256: 156.20617358490574\n",
      "# Predictions:  54\n",
      "mse for window size 255: 154.813350462963\n",
      "# Predictions:  55\n",
      "mse for window size 254: 151.7086181818182\n",
      "# Predictions:  56\n",
      "mse for window size 253: 133.11140714285716\n",
      "# Predictions:  57\n",
      "mse for window size 252: 157.61546315789477\n",
      "# Predictions:  58\n",
      "mse for window size 251: 176.21199137931032\n",
      "# Predictions:  59\n",
      "mse for window size 250: 153.09486101694918\n",
      "# Predictions:  60\n",
      "mse for window size 249: 155.83375541666666\n",
      "# Predictions:  61\n",
      "mse for window size 248: 146.12880819672137\n",
      "# Predictions:  62\n",
      "mse for window size 247: 126.81233082437275\n",
      "# Predictions:  63\n",
      "mse for window size 246: 102.51029682539684\n",
      "# Predictions:  64\n",
      "mse for window size 245: 114.32578636111108\n",
      "# Predictions:  65\n",
      "mse for window size 244: 107.98847692307693\n",
      "# Predictions:  66\n",
      "mse for window size 243: 127.81525303030307\n",
      "# Predictions:  67\n",
      "mse for window size 242: 116.62213731343286\n",
      "# Predictions:  68\n",
      "mse for window size 241: 207.04383970588236\n",
      "# Predictions:  69\n",
      "mse for window size 240: 206.84767391304348\n",
      "# Predictions:  70\n",
      "mse for window size 239: 183.46136035714284\n",
      "# Predictions:  71\n",
      "mse for window size 238: 177.4923285211268\n",
      "# Predictions:  72\n",
      "mse for window size 237: 158.02565917013888\n",
      "# Predictions:  73\n",
      "mse for window size 236: 188.1575429318874\n",
      "# Predictions:  74\n",
      "mse for window size 235: 164.02284039789788\n",
      "# Predictions:  75\n",
      "mse for window size 234: 162.02836911999998\n",
      "# Predictions:  76\n",
      "mse for window size 233: 185.6728947368421\n",
      "# Predictions:  77\n",
      "mse for window size 232: 169.29168632756134\n",
      "# Predictions:  78\n",
      "mse for window size 231: 193.13509572792023\n",
      "# Predictions:  79\n",
      "mse for window size 230: 178.01154600879048\n",
      "# Predictions:  80\n",
      "mse for window size 229: 198.00977920868056\n",
      "# Predictions:  81\n",
      "mse for window size 228: 172.0522182222222\n",
      "# Predictions:  82\n",
      "mse for window size 227: 194.12491674830628\n",
      "# Predictions:  83\n",
      "mse for window size 226: 152.67833590495312\n",
      "# Predictions:  84\n",
      "mse for window size 225: 176.11827342625665\n",
      "# Predictions:  85\n",
      "mse for window size 224: 205.06732988562092\n",
      "# Predictions:  86\n",
      "mse for window size 223: 165.30545623385015\n",
      "# Predictions:  87\n",
      "mse for window size 222: 221.12121948435512\n",
      "# Predictions:  88\n",
      "mse for window size 221: 193.68687660637625\n",
      "# Predictions:  89\n",
      "mse for window size 220: 146.90338376152897\n",
      "# Predictions:  90\n",
      "mse for window size 219: 187.3766530373457\n",
      "# Predictions:  91\n",
      "mse for window size 218: 167.23142080616603\n",
      "# Predictions:  92\n",
      "mse for window size 217: 168.02591919329217\n",
      "# Predictions:  93\n",
      "mse for window size 216: 187.82918835005972\n",
      "# Predictions:  94\n",
      "mse for window size 215: 207.47921079698588\n",
      "# Predictions:  95\n",
      "mse for window size 214: 195.46579314596013\n",
      "# Predictions:  96\n",
      "mse for window size 213: 222.79373209162415\n",
      "# Predictions:  97\n",
      "mse for window size 212: 195.94957791518226\n",
      "# Predictions:  98\n",
      "mse for window size 211: 213.61561037401148\n",
      "# Predictions:  99\n",
      "mse for window size 210: 212.8500679964784\n",
      "# Predictions:  100\n",
      "mse for window size 209: 236.7838763268596\n",
      "# Predictions:  101\n",
      "mse for window size 208: 215.23832124434475\n",
      "# Predictions:  102\n",
      "mse for window size 207: 257.66494667238567\n",
      "# Predictions:  103\n",
      "mse for window size 206: 249.1755722655277\n",
      "# Predictions:  104\n",
      "mse for window size 205: 270.8122304694858\n",
      "# Predictions:  105\n",
      "mse for window size 204: 253.80253807680648\n",
      "# Predictions:  106\n",
      "mse for window size 203: 300.3340034972029\n",
      "# Predictions:  107\n",
      "mse for window size 202: 289.5054787606439\n",
      "# Predictions:  108\n",
      "mse for window size 201: 291.26289389577033\n",
      "# Predictions:  109\n",
      "mse for window size 200: 314.0938741198122\n",
      "# Predictions:  110\n",
      "mse for window size 199: 297.7489576407492\n",
      "# Predictions:  111\n",
      "mse for window size 198: 289.5465674479684\n",
      "# Predictions:  112\n",
      "mse for window size 197: 295.64525488276155\n",
      "# Predictions:  113\n",
      "mse for window size 196: 309.63021107245874\n",
      "# Predictions:  114\n",
      "mse for window size 195: 328.84038871205854\n",
      "# Predictions:  115\n",
      "mse for window size 194: 358.33470366212543\n",
      "# Predictions:  116\n",
      "mse for window size 193: 376.5340658807092\n",
      "# Predictions:  117\n",
      "mse for window size 192: 382.26961987426586\n",
      "# Predictions:  118\n",
      "mse for window size 191: 386.3059889499176\n",
      "# Predictions:  119\n",
      "mse for window size 190: 380.81059837990546\n",
      "# Predictions:  120\n",
      "mse for window size 189: 373.19709325514935\n",
      "# Predictions:  121\n",
      "mse for window size 188: 375.86654873903285\n",
      "# Predictions:  122\n",
      "mse for window size 187: 387.68592864677555\n",
      "# Predictions:  123\n",
      "mse for window size 186: 380.8074103931521\n",
      "# Predictions:  124\n",
      "mse for window size 185: 400.27447847720657\n",
      "# Predictions:  125\n",
      "mse for window size 184: 427.278466929864\n",
      "# Predictions:  126\n",
      "mse for window size 183: 387.03930509312124\n",
      "# Predictions:  127\n",
      "mse for window size 182: 436.08840830868223\n",
      "# Predictions:  128\n",
      "mse for window size 181: 451.8673870294574\n",
      "# Predictions:  129\n",
      "mse for window size 180: 417.2112559361433\n",
      "# Predictions:  130\n",
      "mse for window size 179: 420.38164893913745\n",
      "# Predictions:  131\n",
      "mse for window size 178: 397.5879040871112\n",
      "# Predictions:  132\n",
      "mse for window size 177: 401.27784768942087\n",
      "# Predictions:  133\n",
      "mse for window size 176: 407.97397251060903\n",
      "# Predictions:  134\n",
      "mse for window size 175: 415.6692367342455\n",
      "# Predictions:  135\n",
      "mse for window size 174: 443.62821478230455\n",
      "# Predictions:  136\n",
      "mse for window size 173: 489.16679330519815\n",
      "# Predictions:  137\n",
      "mse for window size 172: 456.9436217252284\n",
      "# Predictions:  138\n",
      "mse for window size 171: 455.9269722425112\n",
      "# Predictions:  139\n",
      "mse for window size 170: 467.1896145986231\n",
      "# Predictions:  140\n",
      "mse for window size 169: 444.3939676048834\n",
      "# Predictions:  141\n",
      "mse for window size 168: 463.95935448996886\n",
      "# Predictions:  142\n",
      "mse for window size 167: 455.6595025178752\n",
      "# Predictions:  143\n",
      "mse for window size 166: 448.0839195244767\n",
      "# Predictions:  144\n",
      "mse for window size 165: 476.1787444577477\n",
      "# Predictions:  145\n",
      "mse for window size 164: 416.20800246723746\n",
      "# Predictions:  146\n",
      "mse for window size 163: 475.4946042180171\n",
      "# Predictions:  147\n",
      "mse for window size 162: 470.78613459802335\n",
      "# Predictions:  148\n",
      "mse for window size 161: 498.73051867196017\n",
      "# Predictions:  149\n",
      "mse for window size 160: 441.93540492458226\n",
      "# Predictions:  150\n",
      "mse for window size 159: 443.81220034034766\n",
      "# Predictions:  151\n",
      "mse for window size 158: 483.3649548952017\n",
      "# Predictions:  152\n",
      "mse for window size 157: 414.928690691831\n",
      "# Predictions:  153\n",
      "mse for window size 156: 454.1988146210262\n",
      "# Predictions:  154\n",
      "mse for window size 155: 448.1087542311656\n",
      "# Predictions:  155\n",
      "mse for window size 154: 451.1127517517044\n",
      "# Predictions:  156\n",
      "mse for window size 153: 448.6258060849884\n",
      "# Predictions:  157\n",
      "mse for window size 152: 417.44603337243177\n",
      "# Predictions:  158\n",
      "mse for window size 151: 467.8966169173126\n",
      "# Predictions:  159\n",
      "mse for window size 150: 409.1606310154176\n",
      "# Predictions:  160\n",
      "mse for window size 149: 452.5190850722116\n",
      "# Predictions:  161\n",
      "mse for window size 148: 392.07640781544006\n",
      "# Predictions:  162\n",
      "mse for window size 147: 426.9659402445104\n",
      "# Predictions:  163\n",
      "mse for window size 146: 454.53635148219337\n",
      "# Predictions:  164\n",
      "mse for window size 145: 410.3220161901755\n",
      "# Predictions:  165\n",
      "mse for window size 144: 396.1723139947055\n",
      "# Predictions:  166\n",
      "mse for window size 143: 403.67865216875845\n",
      "# Predictions:  167\n",
      "mse for window size 142: 412.6808623290087\n",
      "# Predictions:  168\n",
      "mse for window size 141: 410.55215593040714\n",
      "# Predictions:  169\n",
      "mse for window size 140: 387.58055171147623\n",
      "# Predictions:  170\n",
      "mse for window size 139: 407.91877312973855\n",
      "# Predictions:  171\n",
      "mse for window size 138: 391.50697202745954\n",
      "# Predictions:  172\n",
      "mse for window size 137: 352.12027591453426\n",
      "# Predictions:  173\n",
      "mse for window size 136: 402.3697737336093\n",
      "# Predictions:  174\n",
      "mse for window size 135: 380.63345173131285\n",
      "# Predictions:  175\n",
      "mse for window size 134: 384.5208843110886\n",
      "# Predictions:  176\n",
      "mse for window size 133: 428.4463720025961\n",
      "# Predictions:  177\n",
      "mse for window size 132: 372.4305605526884\n",
      "# Predictions:  178\n",
      "mse for window size 131: 388.73266936624935\n",
      "# Predictions:  179\n",
      "mse for window size 130: 383.5044120318704\n",
      "# Predictions:  180\n",
      "mse for window size 129: 325.6258726659337\n",
      "# Predictions:  181\n",
      "mse for window size 128: 359.6075012913331\n",
      "# Predictions:  182\n",
      "mse for window size 127: 351.91452629449583\n",
      "# Predictions:  183\n",
      "mse for window size 126: 337.65214128051\n",
      "# Predictions:  184\n",
      "mse for window size 125: 346.6456245038019\n",
      "# Predictions:  185\n",
      "mse for window size 124: 328.9570719451269\n",
      "# Predictions:  186\n",
      "mse for window size 123: 341.0245319238392\n",
      "# Predictions:  187\n",
      "mse for window size 122: 367.9760380791742\n",
      "# Predictions:  188\n",
      "mse for window size 121: 318.63093841021976\n",
      "# Predictions:  189\n",
      "mse for window size 120: 327.88886258706157\n",
      "# Predictions:  190\n",
      "mse for window size 119: 305.470821645453\n",
      "# Predictions:  191\n",
      "mse for window size 118: 307.3860093616567\n",
      "# Predictions:  192\n",
      "mse for window size 117: 278.1774180581833\n",
      "# Predictions:  193\n",
      "mse for window size 116: 294.49805411782864\n",
      "# Predictions:  194\n",
      "mse for window size 115: 290.93843393538\n",
      "# Predictions:  195\n",
      "mse for window size 114: 312.9354233741787\n",
      "# Predictions:  196\n",
      "mse for window size 113: 315.560847065581\n",
      "# Predictions:  197\n",
      "mse for window size 112: 285.0407392419314\n",
      "# Predictions:  198\n",
      "mse for window size 111: 323.7256723012723\n",
      "# Predictions:  199\n",
      "mse for window size 110: 256.9179462718097\n",
      "# Predictions:  200\n",
      "mse for window size 109: 247.00199022292796\n",
      "# Predictions:  201\n",
      "mse for window size 108: 250.44872650378844\n",
      "# Predictions:  202\n",
      "mse for window size 107: 265.52942211490324\n",
      "# Predictions:  203\n",
      "mse for window size 106: 263.90916862523113\n",
      "# Predictions:  204\n",
      "mse for window size 105: 250.6389068851526\n",
      "# Predictions:  205\n",
      "mse for window size 104: 278.74658744398613\n",
      "# Predictions:  206\n",
      "mse for window size 103: 279.451953392714\n",
      "# Predictions:  207\n",
      "mse for window size 102: 285.65056864290716\n",
      "# Predictions:  208\n",
      "mse for window size 101: 264.6094735431691\n",
      "# Predictions:  209\n",
      "mse for window size 100: 239.27257112206047\n",
      "# Predictions:  210\n",
      "mse for window size 99: 266.95903644103294\n",
      "# Predictions:  211\n",
      "mse for window size 98: 260.69452985116436\n",
      "# Predictions:  212\n",
      "mse for window size 97: 254.0432315168598\n",
      "# Predictions:  213\n",
      "mse for window size 96: 249.1205321916446\n",
      "# Predictions:  214\n",
      "mse for window size 95: 298.26122172773216\n",
      "# Predictions:  215\n",
      "mse for window size 94: 249.36060827768085\n",
      "# Predictions:  216\n",
      "mse for window size 93: 293.18002314081264\n",
      "# Predictions:  217\n",
      "mse for window size 92: 262.16652921216644\n",
      "# Predictions:  218\n",
      "mse for window size 91: 263.44508171312856\n",
      "# Predictions:  219\n",
      "mse for window size 90: 255.87575755891615\n",
      "# Predictions:  220\n",
      "mse for window size 89: 229.8814407568105\n",
      "# Predictions:  221\n",
      "mse for window size 88: 249.685629715617\n",
      "# Predictions:  222\n",
      "mse for window size 87: 267.8968936967784\n",
      "# Predictions:  223\n",
      "mse for window size 86: 238.49288337126688\n",
      "# Predictions:  224\n",
      "mse for window size 85: 263.7482384087049\n",
      "# Predictions:  225\n",
      "mse for window size 84: 226.49301396544783\n",
      "# Predictions:  226\n",
      "mse for window size 83: 257.187218282338\n",
      "# Predictions:  227\n",
      "mse for window size 82: 247.91825369469174\n",
      "# Predictions:  228\n",
      "mse for window size 81: 229.85421641777373\n",
      "# Predictions:  229\n",
      "mse for window size 80: 236.94891042532848\n",
      "# Predictions:  230\n",
      "mse for window size 79: 219.64681977273798\n",
      "# Predictions:  231\n",
      "mse for window size 78: 239.42804879916756\n",
      "# Predictions:  232\n",
      "mse for window size 77: 254.39019354347974\n",
      "# Predictions:  233\n",
      "mse for window size 76: 257.38218941232236\n",
      "# Predictions:  234\n",
      "mse for window size 75: 231.99268823537705\n",
      "# Predictions:  235\n",
      "mse for window size 74: 255.0217554874353\n",
      "# Predictions:  236\n",
      "mse for window size 73: 235.4380643611598\n",
      "# Predictions:  237\n",
      "mse for window size 72: 253.30076098032856\n",
      "# Predictions:  238\n",
      "mse for window size 71: 220.11481923145033\n",
      "# Predictions:  239\n",
      "mse for window size 70: 217.04658355083015\n",
      "# Predictions:  240\n",
      "mse for window size 69: 208.01476834007286\n",
      "# Predictions:  241\n",
      "mse for window size 68: 220.22520908909635\n",
      "# Predictions:  242\n",
      "mse for window size 67: 229.64609099821968\n",
      "# Predictions:  243\n",
      "mse for window size 66: 241.10113157025748\n",
      "# Predictions:  244\n",
      "mse for window size 65: 245.901443589255\n",
      "# Predictions:  245\n",
      "mse for window size 64: 245.77751075558797\n",
      "# Predictions:  246\n",
      "mse for window size 63: 236.08738945276758\n",
      "# Predictions:  247\n",
      "mse for window size 62: 213.00130409753777\n",
      "# Predictions:  248\n",
      "mse for window size 61: 206.49347339861123\n",
      "# Predictions:  249\n",
      "mse for window size 60: 217.6009824740094\n",
      "# Predictions:  250\n",
      "mse for window size 59: 214.21058227827442\n",
      "# Predictions:  251\n",
      "mse for window size 58: 255.84396297253843\n",
      "# Predictions:  252\n",
      "mse for window size 57: 244.45566833030148\n",
      "# Predictions:  253\n",
      "mse for window size 56: 238.58864830534938\n",
      "# Predictions:  254\n",
      "mse for window size 55: 269.15915407575164\n",
      "# Predictions:  255\n",
      "mse for window size 54: 243.53163784052288\n",
      "# Predictions:  256\n",
      "mse for window size 53: 236.06525605316395\n",
      "# Predictions:  257\n",
      "mse for window size 52: 226.49314333754228\n",
      "# Predictions:  258\n",
      "mse for window size 51: 225.42930880278433\n",
      "# Predictions:  259\n",
      "mse for window size 50: 216.79132420907865\n",
      "# Predictions:  260\n",
      "mse for window size 49: 234.1868918616066\n",
      "# Predictions:  261\n",
      "mse for window size 48: 205.74098392797467\n",
      "# Predictions:  262\n",
      "mse for window size 47: 247.78323459830028\n",
      "# Predictions:  263\n",
      "mse for window size 46: 234.93661250047262\n",
      "# Predictions:  264\n",
      "mse for window size 45: 239.60786493622257\n",
      "# Predictions:  265\n",
      "mse for window size 44: 230.26241937276345\n",
      "# Predictions:  266\n",
      "mse for window size 43: 245.71921944041011\n",
      "# Predictions:  267\n",
      "mse for window size 42: 241.89186440257288\n",
      "# Predictions:  268\n",
      "mse for window size 41: 207.08615521842316\n",
      "# Predictions:  269\n",
      "mse for window size 40: 239.615337858845\n",
      "# Predictions:  270\n",
      "mse for window size 39: 232.60736289218394\n",
      "# Predictions:  271\n",
      "mse for window size 38: 247.18799666092238\n",
      "# Predictions:  272\n",
      "mse for window size 37: 245.12389189717604\n",
      "# Predictions:  273\n",
      "mse for window size 36: 244.56894286395385\n",
      "# Predictions:  274\n",
      "mse for window size 35: 225.97667027138678\n",
      "# Predictions:  275\n",
      "mse for window size 34: 236.14274605015464\n",
      "# Predictions:  276\n",
      "mse for window size 33: 216.17837690383786\n",
      "mses:  [  0.7056       0.6565       0.7718       3.276225    10.92104\n",
      "   8.49058333   8.06205714  63.78115     43.44895556  46.40898\n",
      "  56.16667273  37.34453333  56.0038      91.40362857  64.14515333\n",
      " 121.26184375 127.08213529 136.88522778 143.82300526 126.94225\n",
      "  64.38540952 128.19337727  73.74692609 119.5234125  172.169656\n",
      " 190.32449615 190.47737407 249.53916071 168.53487241 177.72337667\n",
      " 199.91672258 157.92517813 231.09201515 215.28378824 195.27602286\n",
      " 221.10798056 192.51491689 191.81672105 235.14686862 209.0681325\n",
      " 189.4532439  211.33112502 173.86708605 198.24176648 200.58127778\n",
      " 195.72231522 200.6495469  207.16734167 181.45819734 183.34136956\n",
      " 174.69412596 177.08924279 156.20617358 154.81335046 151.70861818\n",
      " 133.11140714 157.61546316 176.21199138 153.09486102 155.83375542\n",
      " 146.1288082  126.81233082 102.51029683 114.32578636 107.98847692\n",
      " 127.81525303 116.62213731 207.04383971 206.84767391 183.46136036\n",
      " 177.49232852 158.02565917 188.15754293 164.0228404  162.02836912\n",
      " 185.67289474 169.29168633 193.13509573 178.01154601 198.00977921\n",
      " 172.05221822 194.12491675 152.6783359  176.11827343 205.06732989\n",
      " 165.30545623 221.12121948 193.68687661 146.90338376 187.37665304\n",
      " 167.23142081 168.02591919 187.82918835 207.4792108  195.46579315\n",
      " 222.79373209 195.94957792 213.61561037 212.850068   236.78387633\n",
      " 215.23832124 257.66494667 249.17557227 270.81223047 253.80253808\n",
      " 300.3340035  289.50547876 291.2628939  314.09387412 297.74895764\n",
      " 289.54656745 295.64525488 309.63021107 328.84038871 358.33470366\n",
      " 376.53406588 382.26961987 386.30598895 380.81059838 373.19709326\n",
      " 375.86654874 387.68592865 380.80741039 400.27447848 427.27846693\n",
      " 387.03930509 436.08840831 451.86738703 417.21125594 420.38164894\n",
      " 397.58790409 401.27784769 407.97397251 415.66923673 443.62821478\n",
      " 489.16679331 456.94362173 455.92697224 467.1896146  444.3939676\n",
      " 463.95935449 455.65950252 448.08391952 476.17874446 416.20800247\n",
      " 475.49460422 470.7861346  498.73051867 441.93540492 443.81220034\n",
      " 483.3649549  414.92869069 454.19881462 448.10875423 451.11275175\n",
      " 448.62580608 417.44603337 467.89661692 409.16063102 452.51908507\n",
      " 392.07640782 426.96594024 454.53635148 410.32201619 396.17231399\n",
      " 403.67865217 412.68086233 410.55215593 387.58055171 407.91877313\n",
      " 391.50697203 352.12027591 402.36977373 380.63345173 384.52088431\n",
      " 428.446372   372.43056055 388.73266937 383.50441203 325.62587267\n",
      " 359.60750129 351.91452629 337.65214128 346.6456245  328.95707195\n",
      " 341.02453192 367.97603808 318.63093841 327.88886259 305.47082165\n",
      " 307.38600936 278.17741806 294.49805412 290.93843394 312.93542337\n",
      " 315.56084707 285.04073924 323.7256723  256.91794627 247.00199022\n",
      " 250.4487265  265.52942211 263.90916863 250.63890689 278.74658744\n",
      " 279.45195339 285.65056864 264.60947354 239.27257112 266.95903644\n",
      " 260.69452985 254.04323152 249.12053219 298.26122173 249.36060828\n",
      " 293.18002314 262.16652921 263.44508171 255.87575756 229.88144076\n",
      " 249.68562972 267.8968937  238.49288337 263.74823841 226.49301397\n",
      " 257.18721828 247.91825369 229.85421642 236.94891043 219.64681977\n",
      " 239.4280488  254.39019354 257.38218941 231.99268824 255.02175549\n",
      " 235.43806436 253.30076098 220.11481923 217.04658355 208.01476834\n",
      " 220.22520909 229.646091   241.10113157 245.90144359 245.77751076\n",
      " 236.08738945 213.0013041  206.4934734  217.60098247 214.21058228\n",
      " 255.84396297 244.45566833 238.58864831 269.15915408 243.53163784\n",
      " 236.06525605 226.49314334 225.4293088  216.79132421 234.18689186\n",
      " 205.74098393 247.7832346  234.9366125  239.60786494 230.26241937\n",
      " 245.71921944 241.8918644  207.08615522 239.61533786 232.60736289\n",
      " 247.18799666 245.1238919  244.56894286 225.97667027 236.14274605\n",
      " 216.1783769 ]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all window sizes to determine optimal size\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Change window_size_optimization flag to perform iterations\n",
    "window_size_optimization = False\n",
    "\n",
    "if window_size_optimization == True:\n",
    "\n",
    "    # Fit regression model\n",
    "    params = {'n_estimators': 100}\n",
    "    clf = ensemble.RandomForestRegressor(**params)\n",
    "    \n",
    "    accuracies = np.zeros(276)\n",
    "    mses = np.zeros(276)\n",
    "    #298 accuracy indices\n",
    "\n",
    "    # Iterate over all window sizes and compute accuracy for each LR model\n",
    "    for window_size in range(1,277):\n",
    "    #window_size = 299\n",
    "        print('# Predictions: ', window_size)\n",
    "        X_train = X.iloc[window_size:]\n",
    "        y_train = y.iloc[window_size:]\n",
    "        # print('train labels: ', y_train)\n",
    "        X_test = X.iloc[:window_size]\n",
    "        y_test = y.iloc[:window_size]\n",
    "        # print('test labels: ', y_test)\n",
    "\n",
    "        actuals = pd.DataFrame(y_test)\n",
    "        actuals = actuals.rename(columns={'AvgHR':'Actuals'})\n",
    "        # print('actuals: \\n', actuals)\n",
    "        preds = np.zeros(X_test.shape[0])\n",
    "        # print('X_test: \\n', X_test)\n",
    "        for i in range(0,y_test.shape[0]):\n",
    "            # Fit model\n",
    "            clf.fit(X_train, y_train.values.ravel())\n",
    "            # Predict test set\n",
    "            y_pred = clf.predict(np.array(X_test.iloc[-1]).reshape(1,-1))\n",
    "            preds[i] = y_pred\n",
    "            # Compute mean squared error\n",
    "            mse = mean_squared_error(y_test.iloc[-1], y_pred)\n",
    "            #print('Accuracy of logistic regression classifier on test set {}: {:.2f}'.format(i, logreg.score(X_test, y_test)))\n",
    "            #print(\"X test -1: \", X_test.iloc[-1])\n",
    "            \n",
    "            # Perform LOO cross-validation and add window of test instances to X_train, y_train\n",
    "            X_test_inst = pd.DataFrame(data= [X_test.iloc[-1]],columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "            y_test_inst = pd.DataFrame(data = [y_test.iloc[-1]],columns=[\"AvgHR\"])\n",
    "            #print(\"X test inst: \", X_test_inst)\n",
    "            X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "            X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "            #print(\"X train: \\n\", X_train)\n",
    "\n",
    "            y_train = y_train.drop(y_train.index[-1])\n",
    "            y_train = pd.concat([y_test_inst,y_train])\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "            #print(\"y train \\n\", y_train)\n",
    "\n",
    "            X_test = X_test.drop(X_test.index[-1])\n",
    "            X_test = X_test.reset_index(drop=True)\n",
    "            #print(\"X test: \\n\", X_test)\n",
    "            y_test = y_test.drop(y_test.index[-1])\n",
    "            y_test = y_test.reset_index(drop=True)\n",
    "            \n",
    "        preds_act_df = pd.DataFrame(preds, columns=['Predictions'])\n",
    "        preds_act_df = preds_act_df.join(actuals)\n",
    "        # print('actuals and preds: \\n', preds_act_df)\n",
    "        #accuracy = metrics.accuracy_score(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "        mse_final = metrics.mean_squared_error(preds_act_df.Actuals.ravel(),preds_act_df.Predictions.ravel())\n",
    "        print('mse for window size {}: {}'.format(309-window_size, mse_final))\n",
    "        #accuracies[window_size-1] = accuracy\n",
    "        mses[window_size-1] = mse_final\n",
    "    #print('Accuracies: ', accuracies)\n",
    "    print('mses: ', mses)\n",
    "    # Output accuracies for each window size to Accuracies_for_Window_Size_Variations.csv file \n",
    "    with open('Forest_Accuracies_for_Window_Size_Variations.csv', 'w') as f:\n",
    "        for i in range(0,len(mses)):\n",
    "            f.write(str(308-i) + ': ' + str(mses[i]))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Window Accuracy\n",
      "1      307   0.6565\n",
      "0      308   0.7056\n",
      "2      306   0.7718\n",
      "3      305  3.27622\n",
      "6      302  8.06206\n",
      "5      303  8.49058\n",
      "4      304   10.921\n",
      "11     297  37.3445\n",
      "8      300   43.449\n",
      "9      299   46.409\n",
      "12     296  56.0038\n",
      "10     298  56.1667\n",
      "7      301  63.7811\n",
      "14     294  64.1452\n",
      "20     288  64.3854\n",
      "22     286  73.7469\n",
      "13     295  91.4036\n",
      "62     246   102.51\n",
      "64     244  107.988\n",
      "63     245  114.326\n",
      "66     242  116.622\n",
      "23     285  119.523\n",
      "15     293  121.262\n",
      "61     247  126.812\n",
      "19     289  126.942\n",
      "16     292  127.082\n",
      "65     243  127.815\n",
      "21     287  128.193\n",
      "55     253  133.111\n",
      "17     291  136.885\n",
      "18     290  143.823\n",
      "60     248  146.129\n",
      "88     220  146.903\n",
      "54     254  151.709\n",
      "82     226  152.678\n",
      "58     250  153.095\n",
      "53     255  154.813\n",
      "59     249  155.834\n",
      "52     256  156.206\n",
      "56     252  157.615\n",
      "31     277  157.925\n",
      "71     237  158.026\n",
      "74     234  162.028\n",
      "73     235  164.023\n",
      "85     223  165.305\n",
      "90     218  167.231\n",
      "91     217  168.026\n",
      "28     280  168.535\n",
      "76     232  169.292\n",
      "80     228  172.052\n",
      "24     284   172.17\n",
      "42     266  173.867\n",
      "50     258  174.694\n",
      "83     225  176.118\n",
      "57     251  176.212\n",
      "51     257  177.089\n",
      "70     238  177.492\n",
      "29     279  177.723\n",
      "78     230  178.012\n",
      "48     260  181.458\n",
      "49     259  183.341\n",
      "69     239  183.461\n",
      "75     233  185.673\n",
      "89     219  187.377\n",
      "92     216  187.829\n",
      "72     236  188.158\n",
      "40     268  189.453\n",
      "25     283  190.324\n",
      "26     282  190.477\n",
      "37     271  191.817\n",
      "36     272  192.515\n",
      "77     231  193.135\n",
      "87     221  193.687\n",
      "81     227  194.125\n",
      "34     274  195.276\n",
      "94     214  195.466\n",
      "45     263  195.722\n",
      "96     212   195.95\n",
      "79     229   198.01\n",
      "43     265  198.242\n",
      "30     278  199.917\n",
      "44     264  200.581\n",
      "46     262   200.65\n",
      "84     224  205.067\n",
      "260     48  205.741\n",
      "247     61  206.493\n",
      "68     240  206.848\n",
      "67     241  207.044\n",
      "267     41  207.086\n",
      "47     261  207.167\n",
      "93     215  207.479\n",
      "239     69  208.015\n",
      "39     269  209.068\n",
      "41     267  211.331\n",
      "98     210   212.85\n",
      "246     62  213.001\n",
      "97     211  213.616\n",
      "249     59  214.211\n",
      "100    208  215.238\n",
      "33     275  215.284\n",
      "275     33  216.178\n",
      "258     50  216.791\n",
      "238     70  217.047\n",
      "248     60  217.601\n",
      "229     79  219.647\n",
      "237     71  220.115\n",
      "240     68  220.225\n",
      "35     273  221.108\n",
      "86     222  221.121\n",
      "95     213  222.794\n",
      "257     51  225.429\n",
      "273     35  225.977\n",
      "224     84  226.493\n",
      "256     52  226.493\n",
      "241     67  229.646\n",
      "227     81  229.854\n",
      "219     89  229.881\n",
      "264     44  230.262\n",
      "32     276  231.092\n",
      "233     75  231.993\n",
      "269     39  232.607\n",
      "259     49  234.187\n",
      "262     46  234.937\n",
      "38     270  235.147\n",
      "235     73  235.438\n",
      "255     53  236.065\n",
      "245     63  236.087\n",
      "274     34  236.143\n",
      "99     209  236.784\n",
      "228     80  236.949\n",
      "222     86  238.493\n",
      "252     56  238.589\n",
      "208    100  239.273\n",
      "230     78  239.428\n",
      "263     45  239.608\n",
      "268     40  239.615\n",
      "242     66  241.101\n",
      "266     42  241.892\n",
      "254     54  243.532\n",
      "251     57  244.456\n",
      "272     36  244.569\n",
      "271     37  245.124\n",
      "265     43  245.719\n",
      "244     64  245.778\n",
      "243     65  245.901\n",
      "199    109  247.002\n",
      "270     38  247.188\n",
      "261     47  247.783\n",
      "226     82  247.918\n",
      "212     96  249.121\n",
      "102    206  249.176\n",
      "214     94  249.361\n",
      "27     281  249.539\n",
      "220     88  249.686\n",
      "200    108  250.449\n",
      "203    105  250.639\n",
      "236     72  253.301\n",
      "104    204  253.803\n",
      "211     97  254.043\n",
      "231     77   254.39\n",
      "234     74  255.022\n",
      "250     58  255.844\n",
      "218     90  255.876\n",
      "198    110  256.918\n",
      "225     83  257.187\n",
      "232     76  257.382\n",
      "101    207  257.665\n",
      "210     98  260.695\n",
      "216     92  262.167\n",
      "217     91  263.445\n",
      "223     85  263.748\n",
      "202    106  263.909\n",
      "207    101  264.609\n",
      "201    107  265.529\n",
      "209     99  266.959\n",
      "221     87  267.897\n",
      "253     55  269.159\n",
      "103    205  270.812\n",
      "191    117  278.177\n",
      "204    104  278.747\n",
      "205    103  279.452\n",
      "196    112  285.041\n",
      "206    102  285.651\n",
      "106    202  289.505\n",
      "110    198  289.547\n",
      "193    115  290.938\n",
      "107    201  291.263\n",
      "215     93   293.18\n",
      "192    116  294.498\n",
      "111    197  295.645\n",
      "109    199  297.749\n",
      "213     95  298.261\n",
      "105    203  300.334\n",
      "189    119  305.471\n",
      "190    118  307.386\n",
      "112    196   309.63\n",
      "194    114  312.935\n",
      "108    200  314.094\n",
      "195    113  315.561\n",
      "187    121  318.631\n",
      "197    111  323.726\n",
      "179    129  325.626\n",
      "188    120  327.889\n",
      "113    195   328.84\n",
      "184    124  328.957\n",
      "182    126  337.652\n",
      "185    123  341.025\n",
      "183    125  346.646\n",
      "181    127  351.915\n",
      "171    137   352.12\n",
      "114    194  358.335\n",
      "180    128  359.608\n",
      "186    122  367.976\n",
      "176    132  372.431\n",
      "119    189  373.197\n",
      "120    188  375.867\n",
      "115    193  376.534\n",
      "173    135  380.633\n",
      "122    186  380.807\n",
      "118    190  380.811\n",
      "116    192   382.27\n",
      "178    130  383.504\n",
      "174    134  384.521\n",
      "117    191  386.306\n",
      "125    183  387.039\n",
      "168    140  387.581\n",
      "121    187  387.686\n",
      "177    131  388.733\n",
      "170    138  391.507\n",
      "160    148  392.076\n",
      "164    144  396.172\n",
      "130    178  397.588\n",
      "123    185  400.274\n",
      "131    177  401.278\n",
      "172    136   402.37\n",
      "165    143  403.679\n",
      "169    139  407.919\n",
      "132    176  407.974\n",
      "158    150  409.161\n",
      "163    145  410.322\n",
      "167    141  410.552\n",
      "166    142  412.681\n",
      "151    157  414.929\n",
      "133    175  415.669\n",
      "144    164  416.208\n",
      "128    180  417.211\n",
      "156    152  417.446\n",
      "129    179  420.382\n",
      "161    147  426.966\n",
      "124    184  427.278\n",
      "175    133  428.446\n",
      "126    182  436.088\n",
      "148    160  441.935\n",
      "134    174  443.628\n",
      "149    159  443.812\n",
      "139    169  444.394\n",
      "142    166  448.084\n",
      "153    155  448.109\n",
      "155    153  448.626\n",
      "154    154  451.113\n",
      "127    181  451.867\n",
      "159    149  452.519\n",
      "152    156  454.199\n",
      "162    146  454.536\n",
      "141    167   455.66\n",
      "137    171  455.927\n",
      "136    172  456.944\n",
      "140    168  463.959\n",
      "138    170   467.19\n",
      "157    151  467.897\n",
      "146    162  470.786\n",
      "145    163  475.495\n",
      "143    165  476.179\n",
      "150    158  483.365\n",
      "135    173  489.167\n",
      "147    161  498.731\n"
     ]
    }
   ],
   "source": [
    "# Read in accuracies for each window size from Accuracies_for_Window_Size_Variations.csv file and sort by accuracy to determine best window size\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "mylist = pd.DataFrame(columns=['Window', 'Accuracy'])\n",
    "with open('Forest_Accuracies_for_Window_Size_Variations.csv', 'r') as csvfile:\n",
    "    for i,row in enumerate(csv.reader(csvfile, delimiter='\\n')):\n",
    "        mylist.loc[i,'Window'] = row[0].split(':')[0]\n",
    "        mylist.loc[i,'Accuracy'] = float(row[0].split(':')[1])\n",
    "print(mylist.sort_values('Accuracy', 0,ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions:  7\n",
      "Window Size:  302\n",
      "\n",
      "\n",
      "look ahead:  1\n",
      "# iterations:  7\n",
      "predictions:  [156.06]\n",
      "actuals:  [158.]\n",
      "predictions:  [159.33]\n",
      "actuals:  [155.]\n",
      "predictions:  [153.52]\n",
      "actuals:  [155.]\n",
      "predictions:  [158.08]\n",
      "actuals:  [161.]\n",
      "predictions:  [157.73]\n",
      "actuals:  [159.]\n",
      "predictions:  [156.81]\n",
      "actuals:  [158.]\n",
      "predictions:  [159.76]\n",
      "actuals:  [158.]\n",
      "mses:  [ 3.7636 18.7489  2.1904  8.5264  1.6129  1.4161  3.0976]\n",
      "avg mse:  5.622271428571427\n",
      "\n",
      "\n",
      "look ahead:  2\n",
      "# iterations:  4\n",
      "predictions:  [156.06 159.57]\n",
      "actuals:  [158. 155.]\n",
      "predictions:  [153.22 157.97]\n",
      "actuals:  [155. 161.]\n",
      "predictions:  [157.83 157.2 ]\n",
      "actuals:  [159. 158.]\n",
      "predictions:  [158.38]\n",
      "actuals:  [158.]\n",
      "mses:  [12.32425  6.17465  1.00445  0.1444 ]\n",
      "avg mse:  4.91193749999999\n",
      "\n",
      "\n",
      "look ahead:  3\n",
      "# iterations:  3\n",
      "predictions:  [155.94 158.28 154.11]\n",
      "actuals:  [158. 155. 155.]\n",
      "predictions:  [157.02 157.33 157.21]\n",
      "actuals:  [161. 159. 158.]\n",
      "predictions:  [158.95]\n",
      "actuals:  [158.]\n",
      "mses:  [5.2647 6.4178 0.9025]\n",
      "avg mse:  4.194999999999977\n",
      "\n",
      "\n",
      "look ahead:  4\n",
      "# iterations:  2\n",
      "predictions:  [155.99 159.23 153.43 158.43]\n",
      "actuals:  [158. 155. 155. 161.]\n",
      "predictions:  [157.05 156.38 158.18]\n",
      "actuals:  [159. 158. 158.]\n",
      "mses:  [7.7507 2.1531]\n",
      "avg mse:  4.951899999999973\n",
      "\n",
      "\n",
      "look ahead:  5\n",
      "# iterations:  2\n",
      "predictions:  [156.08 158.71 153.41 157.84 156.84]\n",
      "actuals:  [158. 155. 155. 161. 159.]\n",
      "predictions:  [156.51 158.85]\n",
      "actuals:  [158. 158.]\n",
      "mses:  [6.92596 1.4713 ]\n",
      "avg mse:  4.198630000000002\n",
      "\n",
      "\n",
      "look ahead:  6\n",
      "# iterations:  2\n",
      "predictions:  [156.3  159.37 153.72 157.41 157.74 157.28]\n",
      "actuals:  [158. 155. 155. 161. 159. 158.]\n",
      "predictions:  [158.41]\n",
      "actuals:  [158.]\n",
      "mses:  [6.43656667 0.1681    ]\n",
      "avg mse:  3.302333333333333\n",
      "\n",
      "\n",
      "look ahead:  7\n",
      "# iterations:  1\n",
      "predictions:  [156.39 159.42 153.3  157.59 157.74 156.98 160.28]\n",
      "actuals:  [158. 155. 155. 161. 159. 158. 158.]\n",
      "mses:  [6.35328571]\n",
      "avg mse:  6.353285714285696\n",
      "Averages:      Avg MSE\n",
      "0  5.622271\n",
      "1  4.911937\n",
      "2  4.195000\n",
      "3  4.951900\n",
      "4  4.198630\n",
      "5  3.302333\n",
      "6  6.353286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import statistics as stats\n",
    "# Run GB with optimal window size of 302 (# predictions = 7) for all look ahead values from 1 to 7\n",
    "\n",
    "window_size = 7 # num of preds, window_size = 309-window_size param\n",
    "print('# Predictions: ', window_size)\n",
    "print('Window Size: ', 309-window_size)\n",
    "avg_mses = np.zeros(window_size)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "for m in range(1,window_size+1):\n",
    "    # train set\n",
    "    X_train = X.iloc[window_size:]\n",
    "    y_train = y.iloc[window_size:]\n",
    "    #print('train labels: ', y_train)\n",
    "    # test set\n",
    "    X_test = X.iloc[:window_size]\n",
    "    y_test = y.iloc[:window_size]\n",
    "    #print('test labels: ', y_test)\n",
    "    \n",
    "    #look_ahead = 7\n",
    "    look_ahead=m\n",
    "    print(\"\\n\\nlook ahead: \", m)\n",
    "    print(\"# iterations: \", math.ceil(y_test.shape[0]/look_ahead))\n",
    "    \n",
    "    mses = np.zeros(math.ceil(y_test.shape[0]/look_ahead))\n",
    "\n",
    "    for i in range(0,math.ceil(y_test.shape[0]/look_ahead)):\n",
    "        preds = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "        actuals_look_ahead = np.zeros(min(look_ahead,y_test.shape[0]))\n",
    "        # print('Iteration: ', i)\n",
    "        # print('X train shape: ', X_train.shape[0])\n",
    "        # print('X test shape: ', y_test.shape[0])\n",
    "        # Fit model\n",
    "        clf.fit(X_train, y_train.values.ravel())\n",
    "        # Predict test set\n",
    "        for j in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "            y_pred = clf.predict(np.array(X_test.iloc[-j]).reshape(1,-1))\n",
    "            # print('actual: ',y_test.iloc[-j], '\\n pred: ',y_pred, '\\n')\n",
    "            preds[j-1] = y_pred\n",
    "            actuals_look_ahead[j-1] = y_test.iloc[-j]\n",
    "        \n",
    "        # Perform cross-validation and add window of test instances to X_train, y_train\n",
    "        #print(\"X test -1: \", X_test.iloc[-1])\n",
    "        X_test_inst = pd.DataFrame(columns=[\"Distance (km)\",\"Avg Pace (/km)\", \"HRSS\", \"Elevation Gain (m)\"])\n",
    "        y_test_inst = pd.DataFrame(columns=[\"AvgHR\"])\n",
    "        for k in range(1,min(look_ahead+1,y_test.shape[0]+1)):\n",
    "            X_test_inst = X_test_inst.append(X_test.iloc[-k])\n",
    "            y_test_inst = y_test_inst.append(y_test.iloc[-k])        \n",
    "        #print(\"X test inst: \", X_test_inst)\n",
    "\n",
    "        #X_train = X_train.drop(X_train.index[-1]).reset_index(drop=True)\n",
    "        X_train = pd.concat([X_test_inst,X_train]).reset_index(drop = True)\n",
    "        #print(\"X train: \\n\", X_train)\n",
    "\n",
    "        #y_train = y_train.drop(y_train.index[-1])\n",
    "        y_train = pd.concat([y_test_inst,y_train]).reset_index(drop=True)\n",
    "        #print(\"y train \\n\", y_train)\n",
    "\n",
    "        X_test = X_test.drop(X_test_inst.index.values)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        #print(\"X test: \\n\", X_test)\n",
    "\n",
    "        y_test = y_test.drop(y_test_inst.index.values)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        preds_act_df = pd.DataFrame(preds)\n",
    "        act_df = pd.DataFrame(actuals_look_ahead)\n",
    "        print(\"predictions: \", preds)\n",
    "        print(\"actuals: \", actuals_look_ahead)\n",
    "     \n",
    "        # Compute mean squared error\n",
    "        mse = metrics.mean_squared_error(preds,actuals_look_ahead)\n",
    "    \n",
    "        mses[i] = mse\n",
    "    \n",
    "    print('mses: ', mses)\n",
    "    avg_mse = stats.mean(mses)\n",
    "    print('avg mse: ', avg_mse)\n",
    "    avg_mses[m-1] = avg_mse\n",
    "\n",
    "avg_acc_df = pd.DataFrame(data=avg_mses, columns=['Avg MSE'])\n",
    "print('Averages: ', avg_acc_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
